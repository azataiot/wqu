{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to wqu","text":"<p>wqu is an open-source, community-driven project dedicated to fostering collaboration, sharing, and learning.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>Full docs are available at wqu Documentation.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":""},{"location":"#derivative-pricing","title":"Derivative Pricing","text":""},{"location":"#contributing","title":"Contributing","text":"<p>We welcome all kinds of contributions\u2014whether it\u2019s code, documentation, or examples. To get started, please make sure you have a solid background in one or more of the following areas:</p> <ul> <li>Python &amp; Scientific Libraries   NumPy, pandas, matplotlib, SciPy, scikit\u2011learn, PyTorch  </li> <li>Documentation Tools   Markdown, LaTeX  </li> </ul> <p>Ready to contribute? - Join the conversation on our GitHub Discussions. - Found a bug or have a feature request? Let us know via our Issue Tracker.</p> <p>Thank you for helping make wqu better!</p>"},{"location":"Derivative%20Pricing/01-index/","title":"Derivative Pricing","text":""},{"location":"Derivative%20Pricing/01-index/#tldr","title":"TL;DR","text":"<p>Derivative pricing refers to the process of determining the fair value of a derivative financial instrument, such as an option, future, or swap. It involves using mathematical models and market data to calculate the theoritical price of the derivative based on factors like the underlying asset's price, volatility, time to expiration, and interest rates. </p>"},{"location":"Derivative%20Pricing/01-index/#participants","title":"Participants","text":""},{"location":"Derivative%20Pricing/01-index/#buy-side","title":"Buy side","text":"<p>Derivatives on the buy-side refer to financial institutions, such as investment funds or asset managers, that purchase derivative contracts like options, futures, or swaps to manage risk or gain exposure to certain assets or markets. </p>"},{"location":"Derivative%20Pricing/01-index/#sell-side","title":"Sell side","text":"<p>Derivatives on the sell-side refer to financial institutions, such as investment banks, that create, market, and trade derivative products like futures, options, and swaps. The sell-side provides these derivative instruments to clients, such as hedge funds and institutional investors, to help them manage financial risks or speculate on market movements. </p>"},{"location":"Derivative%20Pricing/01-index/#equity-options","title":"Equity Options","text":""},{"location":"Derivative%20Pricing/01-index/#features","title":"Features","text":"<ul> <li>Call vs. Put </li> <li>Moneyness &amp; Liquidity -&gt; OTM/ATM/ITM ?</li> <li>European vs. American vs. Asian -&gt; Early exercise? </li> <li>Non-linear payoffs </li> <li>Leverage -&gt; e.g., 100 shares of underlying stock </li> <li>OTC vs. Exchange traded -&gt; credit risk ? </li> <li>Exposure to volatility -&gt; e.g., Butterfly / Stradles </li> </ul>"},{"location":"Derivative%20Pricing/01-index/#payoff","title":"Payoff","text":"<p>Call Option: \\((S_t - K)^+ = max(S_t - K;0)\\)</p> <p>Put Option: \\((K-S_t)^+ = max(K-S_t;0)\\)</p>"},{"location":"Derivative%20Pricing/01-index/#price-process","title":"Price Process","text":"<p>The essential characteristics of a derivative is that it's payoff depends on the evolution of an underlying asset (e.g., a stock for equity options)</p> <p>Thus a key aspect for pricing (and our first step) is to model the future evolution of the underlying asset.</p> <p>Techniques for modeling underlying stock price evolution: </p> <ul> <li> <p>Binomial Model </p> <p>Binomial model assumes that stock price can make, at any point in time, upward (u) or downward (d) movements. </p> </li> </ul>"},{"location":"Derivative%20Pricing/01-index/#risk-neutral-valuation","title":"Risk-neutral valuation","text":"<p>Prices are computed under a risk-neutral measure, where expected returns are discounted at the risk-free rate rather than the actual expected return. </p> <p>The risk-neutral probability is derived as:</p> \\[ p = \\frac{e^{rT}-d}{u-d} \\] <p>Where: - \\(r\\): the risk free interest rate  - \\(u,d\\): up and down factors  - \\(T\\): Time to maturity </p> <p>Then the price of a European call option becomes :</p> \\[ C_0 = e^{-rT}[pc_u + (1-p)c_d] \\] <p>where \\(c_u,c_d\\) are the call payoffs in up and down states. </p>"},{"location":"Derivative%20Pricing/02-binomial-tree/","title":"Binomial Tree for Option Pricing","text":"<p>For the following data: </p> Text Only<pre><code>S0 = 100\nT = 1\nu = 1.2 \nd = 0.8 \nN = 2\n</code></pre> <p>We have:</p> <pre><code>\ngraph LR\n    S0[\"S\u2080 = 100\"]\n    S1H[\"S\u2081(H) = 120\"]\n    S1T[\"S\u2081(T) = 80\"]\n    S2HH[\"S\u2082(HH) = 144\"]\n    S2HT[\"S\u2082(HT) = 96\"]\n    S2TH[\"S\u2082(TH) = 96\"]\n    S2TT[\"S\u2082(TT) = 64\"]\n\n    S0 --&gt; S1H\n    S0 --&gt; S1T\n    S1H --&gt; S2HH\n    S1H --&gt; S2HT\n    S1T --&gt; S2TH\n    S1T --&gt; S2TT</code></pre> <p>When using paths, the number of paths in the binomial tree is equal to the \\(2^N\\)</p> <p>Note that in the Cox-Ross-Rubinstein (CRR) model (i.e., NumPy style matrix), we only track distinct price levels, not every path- so it\u2019s much more memory efficient in calculation but loses the intuitive path flavor. </p> <p>Which can be implemented as this :</p> Python<pre><code>import numpy as np\n\ndef binomial_call(S0, K, T, r, u, d, N):\n    \"\"\"\n    Computes the price of a European call option using the binomial tree model.\n\n    Args:\n        S0 (float): Initial stock price.\n        K (float): Strike price of the option.\n        T (float): Time to maturity (in years).\n        r (float): Risk-free interest rate (annualized).\n        u (float): Upward movement factor for the stock price.\n        d (float): Downward movement factor for the stock price.\n        N (int): Number of time steps in the binomial tree.\n\n    Returns:\n        float: The price of the European call option.\n        np.ndarray: The option value tree.\n        np.ndarray: The stock price tree.\n    \"\"\"\n    dt = T / N  # Time step size\n    disc = np.exp(-r * dt)  # Discount factor for one time step\n    q = (np.exp(r * dt) - d) / (u - d)  # Risk-neutral probability\n\n    # Initialize trees for stock prices and option values\n    S = np.zeros((N + 1, N + 1))  # Stock price tree\n    C = np.zeros((N + 1, N + 1))  # Option value tree\n\n    # Compute terminal stock prices and option payoffs\n    for i in range(N + 1):\n        S[N, i] = S0 * (u ** i) * (d ** (N - i))  # Stock price at maturity\n        C[N, i] = max(S[N, i] - K, 0)  # Payoff for a call option at maturity\n\n    # Perform backward induction to calculate option values at earlier nodes\n    for j in range(N - 1, -1, -1):  # Iterate over time steps in reverse\n        for i in range(j + 1):  # Iterate over nodes at each time step\n            S[j, i] = S0 * (u ** i) * (d ** (j - i))  # Stock price at node\n            # Option value is the discounted expected value of future payoffs\n            C[j, i] = disc * (q * C[j + 1, i + 1] + (1 - q) * C[j + 1, i])\n\n    # Return the option price, option value tree, and stock price tree\n    return C[0, 0], C, S\n</code></pre> <p>And:    </p> \\[ S[j, i] = S\u2080 \u00d7 u^i \u00d7 d^{(j\u2212i)} \\] <p>where:</p> <ul> <li>j = time step (row)</li> <li>i = number of up moves </li> </ul> <p>To find the europian call option price, underlying stock tree and payoffs using binomial model, we can do:</p> Python<pre><code>from wqu.dp.binomial import binomial_call\n\n\n# binomial_call(S0, K, T, r, u, d, N)\nc0,_,_ = binomial_call(100, 90, 10, 0, 1.2, 0.8, 10)\n</code></pre>"},{"location":"Derivative%20Pricing/03-put-call-parity/","title":"Put-call Parity","text":""},{"location":"Derivative%20Pricing/03-put-call-parity/#tldr","title":"TL;DR","text":"<p>Put-call parity is a fundamental relationship in options pricing that states that the price of a European call option and a European put option with the same strike price and expiration date should be equal, after accounting for the present value of the strike price. This relationship helps ensure no arbitrage opportunity exists between the call and put options on the same underlying asset. </p>"},{"location":"Derivative%20Pricing/03-put-call-parity/#replicating-portfolios","title":"Replicating portfolios","text":"<p>An option ( call or put ) can be replicated with a self-financed portfolio combining:</p> <ol> <li>A position (long or short) in shares </li> <li>A position in a risk-free bond (lend or borrow)</li> </ol>"},{"location":"Derivative%20Pricing/03-put-call-parity/#replicating-portfolio-for-a-call-option","title":"Replicating portfolio for a call option","text":"<pre><code>graph LR\n    S0[\"S\u2080 = 100\"] --&gt;|up| Su[\"S\u1d58 = 120&lt;br&gt;&lt;span style='color:red'&gt;c\u2081\u1d58 = 30&lt;/span&gt;\"]\n    S0 --&gt;|down| Sd[\"S\u1d48 = 80&lt;br&gt;&lt;span style='color:red'&gt;c\u2081\u1d48 = 0&lt;/span&gt;\"]</code></pre> <p>With X number of shares and B amount in the risk-free bond, such that ( assume r=0 for simlicity) </p> \\[ \\begin{aligned} C_1^u = max(120-90,0) = 30 \\\\ C_1^d = max(80-90,0) = 0 \\end{aligned} \\] <p>We want to replicate this payoff using: </p> <ul> <li>X: number of shares </li> <li>B: money in the risk-free bond</li> </ul> <p>we setup the same system:</p> \\[ \\begin{aligned} X \\cdot 120 + B = 30 \\text{ (up)} \\\\ X \\cdot 80 + B = 0 \\text{ (down)} \\end{aligned} \\] <p>After solving the system of equations we get: X= 0.75, B = -60. </p> <p>Initial cost of the portfolio: </p> <p>At time 0, </p> \\[ C_0 = 0.75 \\cdot S_0 + B = 0.75 \\cdot 100 - 60 = 75 - 60 = 15 \\] <p>So, we are replicated that when K=90, </p> <ul> <li>Borrow 60$ </li> <li>Buy 0.75 shares </li> </ul> <p>Total initial cost: $15, that is the fair no-arbitrage price of the option. </p>"},{"location":"Derivative%20Pricing/03-put-call-parity/#replicating-portfolio-for-a-put-option","title":"Replicating portfolio for a put option","text":"<pre><code>graph LR\n    S0[\"S\u2080 = 100\"] --&gt;|up| Su[\"S\u1d58 = 120&lt;br&gt;&lt;span style='color:red'&gt;p\u2081\u1d58 = 0&lt;/span&gt;\"]\n    S0 --&gt;|down| Sd[\"S\u1d48 = 80&lt;br&gt;&lt;span style='color:red'&gt;p\u2081\u1d48 = 10&lt;/span&gt;\"]</code></pre> \\[ \\begin{aligned} X \\cdot 120 + B = 0 \\text{ (up)} \\\\ X \\cdot 80 + B = 10 \\text{ (down)} \\end{aligned} \\] <p>Solving above we get: X = -0.25, B = 30.</p> <p>So we have: \\(100*(-0.25)+30 = 5\\)</p> <p>So the put option price is $5</p>"},{"location":"Derivative%20Pricing/03-put-call-parity/#put-call-parity_1","title":"Put-call parity","text":"<p>Put-call parity shows the exact mathematical relationship between the price of a European call option and a European put option with the same: </p> <ul> <li>Strike price \\(K\\) </li> <li>Expiration time \\(T\\) </li> <li>Underlying asset \\(S_0\\)</li> </ul> \\[ \\begin{aligned} c_0 &amp;= 0.75 S_0 - 60 e^{-rT} \\\\ p_0 &amp;= -0.25 S_0 + 30 e^{-rT} \\end{aligned} \\] <p>A call option can be replicated as long stock + short bond, a put option can be replicated as short stock + long bond. </p> <p>At \\(t_1\\) the stock is either \\(S_u=120\\) or \\(S_d=80\\), Strike price is \\(K=90\\), call payoff is \\(C^u = 30, C^d=0\\), put payoff is \\(P^u=0, P^d=10\\), </p> <p>we solve two systems of linear equations ( for call and for put) using:</p> <p>Stock component + Bond component = Option payoff in each state, </p> <p>then we get:</p> \\[ \\begin{aligned} C_0 + 90e^{-rT} = S_0 + P_0 \\end{aligned} \\] <p>but the 90 is the K, so we can write it as:</p> \\[ \\begin{aligned} C_0 + Ke^{-rT} = S_0 + P_0 \\end{aligned} \\] <p>To get the Put option price we can either use one of the following:</p> Python<pre><code>from wqu.dp.binomial import binomial_put\n\n# binomial_put(S0, K, T, r, u, d, N)\np0 = binomial_put(100, 90, 10, 0, 1.2, 0.8, 10)\n</code></pre> <p>or </p> Python<pre><code>from wqu.dp import put_from_call\n# binomial_put_from_call(S0, K, T, r, call_price)\np0 = put_from_call(100,90,10,0,29.38454450999999)\n</code></pre>"},{"location":"Derivative%20Pricing/04-delta-delta-hedging/","title":"Delta and Delta Hedging","text":"<p>Delta (\\(\\Delta\\)) measures the change in the price of the option with respect to the change in the price of the underlying asset. </p> <p>$$ \\begin{aligned} \\Delta_0 = \\frac{c_1^u - c_1^d}{S_u - S_d} \\end{aligned} $$ </p> <p>Delta is like an insurance policy:</p> <ul> <li>If your option loses value, your stock position will gain (or vice versa)</li> <li>You\u2019re hedging - like carrying an umbrella just in case it rains. </li> </ul> <pre><code>graph LR\n    S0[Stock = 100]\n    S0 --&gt; Su[Stock = 120]\n    S0 --&gt; Sd[Stock = 80]\n\n    Su --&gt; Cu[Call Payoff = 30]\n    Sd --&gt; Cd[Call Payoff = 0]</code></pre> <p>The option pays if the stock goes above strike price ( K=90 )</p> <p>So:</p> <ul> <li>Cu = max(120 - 90, 0) = 30</li> <li>Cd = max(80 - 90, 0) = 0</li> </ul> <p>Delta formulates to:</p> \\[ \\Delta = \\frac{C_u - C_d}{S_u - S_d} = \\frac{30 - 0}{120 - 80} = 0.75 \\] <p>So for every 1 share of call sold, buy 0.75 shares of stock to hedge. </p> <p>For simple 1 step binomial tree, we can calculate delta by:</p> Python<pre><code>from wqu.dp.binomial import calculate_delta\n\n# Inputs\nS0 = 100\nK = 90\nu = 1.2\nd = 0.8\n\n# Calculate delta for call\ndelta_call = calculate_delta(S0, K, u, d, option_type='call')\nprint(f\"Delta (Call): {delta_call:.4f}\")\n\n# Calculate delta for put\ndelta_put = calculate_delta(S0, K, u, d, option_type='put')\nprint(f\"Delta (Put): {delta_put:.4f}\")\n</code></pre>"},{"location":"Derivative%20Pricing/04-delta-delta-hedging/#delta-and-delta-hedging-in-n-step-binomial-tree","title":"Delta and Delta hedging in N-step binomial tree","text":"<p>In a 1-step tree, delta is calculated using the terminal payoffs. </p> <p>In an N-step tree, delta is calculated at each node as: </p> \\[ \\Delta_{t,i} = \\frac{C_{t+1,i+1} - C_{t+1,i}}{S_{t+1,i+1} - S_{t+1,i}} \\] <p>This is just applying the same logic at every point in the tree (going backwards in time).</p> <p>And the Python package <code>wqu</code> provides an easy to use interface for implementing all those. Here is a simplified summary of how it works:</p> <ol> <li>We model the stock price over time as a tree ( it can go up u or down d)</li> <li>Compute the option payoff at each terminal node. </li> <li>Use backward induction to compute the option value at earlier nodes using expected (risk-nutral) values </li> <li>Optionally compute the \\(\\Delta\\) (delta) values - the number of shares you\u2019d need to hedge an option position. </li> <li>Check put-call parity - a relationship that must always hold under no-arbitrage conditions. </li> </ol> <p>Where, we have \\(dt = T / N\\) represents the length of each time step and \\(p=\\frac{e^{r\\Delta t}-d}{u-d}\\), this ensures the model is free of arbitrage and consistent with expected returns under risk-free rate. And \\(discount=e^{-r\\Delta t}\\).</p>"},{"location":"Derivative%20Pricing/04-delta-delta-hedging/#risk-free-measure","title":"Risk free measure","text":"<p>Expected stock price under risk-neutral measure</p> <p>We define:</p> \\[ \\mathbb{E}^{\\mathbb{Q}}[S_{\\Delta t}] = p \\cdot S_0 u + (1 - p) \\cdot S_0 d = S_0 \\cdot (p u + (1 - p) d) \\] <p>In the risk-neutral world, the expected return is the risk-free rate (We get same result if we buy the stock or we put that money in the bond)</p> <p>That means the expected stock value in the future (1 step ahead) is just the current price compounded at the risk-free rate: </p> \\[ \\mathbb{E}^{\\mathbb{Q}}[S_{\\Delta t}] = S_0 \\cdot e^{r \\Delta t} \\] <p>Equating both sides</p> \\[ S_0 \\cdot (p u + (1 - p) d) = S_0 \\cdot e^{r \\Delta t} \\] <p>Cancel S_0 (non-zero), and solve for p: and we get: </p> \\[ \\boxed{p = \\frac{e^{r \\Delta t} - d}{u - d}} \\] <p>That\u2019s our risk-neutral probability.</p>"},{"location":"Derivative%20Pricing/04-delta-delta-hedging/#stock-price-tree","title":"Stock price tree","text":"<p>Binomial stock price tree can be build numerically with :</p> \\[ S_{t,i} = S_0 \\cdot u^i \\cdot d^{t-i} \\] <p>which represents the stock price after \\(i\\) up moves and \\(t-i\\) down moves. This tree represents the possible future paths of the stock over \\(N\\) steps. </p>"},{"location":"Derivative%20Pricing/04-delta-delta-hedging/#option-value-tree","title":"Option value tree","text":"<p>To calculate the option value in any node, we do two things: </p> <ol> <li>Calculate the payoff at maturity t=N, </li> <li>Move backward in time, use the expected risk-neutral value formulated as:</li> </ol> \\[ C_{t, i} = e^{-r \\Delta t} \\left[ p C_{t+1,i+1} + (1 - p) C_{t+1,i} \\right] \\] <p>This is just the present value of expected payoff under the risk-neutral measure. </p>"},{"location":"Derivative%20Pricing/04-delta-delta-hedging/#hedge","title":"Hedge","text":"<p>For each non-terminal node, it computes </p> \\[ \\Delta_{t, i} = \\frac{C_{t+1,i+1} - C_{t+1,i}}{S_{t+1,i+1} - S_{t+1,i}} \\] <p>This tells you:</p> <p>\u2022   How sensitive the option is to changes in the stock price \u2022   How many shares to hold to replicate the option payoff at that node (important in hedging)</p>"},{"location":"Derivative%20Pricing/04-delta-delta-hedging/#price-of-the-option-at-time-t0","title":"Price of the Option at time t=0","text":"<p>To get the option price at time 0, we just need to get the option value \\(C_{0,0}\\) (or \\(P_{0,0}\\) for put)</p> <p>This is the fair value today of the option, computed using all the logic above. </p>"},{"location":"Derivative%20Pricing/04-delta-delta-hedging/#calculation","title":"Calculation","text":"Python<pre><code>bt_call = BinomialTree(S0=100, K=90, T=1, r=0.1, u=1.2, d=0.8, N=3, option_type='call')\nbt_call.build_stock_tree()\nbt_call.build_option_tree()\nbt_call.build_delta_tree()\n\nbt_call.summary()\nbt_call.plot_tree(bt_call.stock_tree, title=\"Stock Price Tree\")\nbt_call.plot_tree(bt_call.option_tree, title=\"Option Price Tree\")\nbt_call.plot_tree(bt_call.delta_tree, title=\"Delta Tree\")\n\nbt_call.check_put_call_parity()\n</code></pre>"},{"location":"Derivative%20Pricing/04-delta-delta-hedging/#risk-neutral-vs-real-world-probabilities","title":"Risk-Neutral vs. Real-World Probabilities","text":"Risk-Neutral World (\\(\\mathbb{Q}\\)) Real World (\\(\\mathbb{P}\\)) Expected return = risk-free rate \\(r\\) Expected return = market drift \\(\\mu\\) Used for pricing Used for prediction Based on no-arbitrage Based on observed outcomes Discounting at \\(e^{-r \\Delta t}\\) Discounting at \\(e^{-\\mu \\Delta t}\\) <p>So we have: </p> \\[ p = \\frac{e^{r \\Delta t} - d}{u - d} \\quad , \\quad p^* = \\frac{e^{\\mu \\Delta t} - d}{u - d} \\] <p>Where $ p^*$ is the real-world probability. </p>"},{"location":"Derivative%20Pricing/04-delta-delta-hedging/#matching-volatility-where-u-and-d-come-from","title":"Matching volatility - where \\(u\\) and \\(d\\) come from","text":"<p>To ensure that the binomial model reflects real-world  volatility \\(\\sigma\\) , we should set:</p> \\[ u = e^{\\sigma \\sqrt{\\Delta t}}, \\quad d = e^{-\\sigma \\sqrt{\\Delta t}} \\] <p>We want to build a binomial tree where the variance of returns matches the real-world (or risk-neutral) volatility of the underlying asset. </p> <p>This lets us: </p> <ul> <li>Model the undertainty of stock movements correctly </li> <li>Ensure convergence to Black-Scholes as \\(N-&gt;\\infty\\)</li> </ul> <p>In the continious world (as in the Black-Sholes), the stock market follows Gemetric Brownian Motion:</p> \\[ \\frac{dS_t}{S_t} = \\mu dt + \\sigma dW_t \\] <p>This implies the log-returns over a small time \\(\\Delta t\\) have variance: </p> \\[ \\text{Var}[\\log(S_{t+\\Delta t} / S_t)] = \\sigma^2 \\Delta t \\] <p>So we want our binomial model to have the same variance! </p> <p>If a stock moves from price \\(S\\) to \\(S{\\prime}\\), the log-return is: \\(\\log\\left(\\frac{S{\\prime}}{S}\\right)\\)</p> <p>So if the stock goes up by a factor u: \\(\\log\\left(\\frac{S_0 \\cdot u}{S_0}\\right) = \\log(u)\\) , Similarly, for a down factor d: \\(\\log(d)\\) </p> <p>These log-returns are additive, and in continuous models, they follow a normal distribution.</p> <p>In the binomial model, one step gives:</p> <ul> <li>Up move: \\(\\log(u) = \\log(e^{\\sigma \\sqrt{\\Delta t}}) = \\sigma \\sqrt{\\Delta t}\\) </li> <li>Down move: \\(\\log(d) = \\log(e^{-\\sigma \\sqrt{\\Delta t}}) = -\\sigma \\sqrt{\\Delta t}\\)</li> </ul> <p>So the returns (log-space) are symmetric: \\(+\\sigma \\sqrt{\\Delta t}\\) or \\(-\\sigma \\sqrt{\\Delta t}\\)</p> <p>We are choosing: \\(u = e^{\\sigma \\sqrt{\\Delta t}}, \\quad d = e^{-\\sigma \\sqrt{\\Delta t}}\\)</p> <p>Now just apply the logarithm: </p> \\[ \\begin{aligned} \\log(u) &amp;= \\log\\left(e^{\\sigma \\sqrt{\\Delta t}}\\right) = \\sigma \\sqrt{\\Delta t} \\\\ \\log(d) &amp;= \\log\\left(e^{-\\sigma \\sqrt{\\Delta t}}\\right) = -\\sigma \\sqrt{\\Delta t} \\end{aligned} \\] <p>This is just applying the basic logarithmic rule: </p> \\[ \\log(e^x) = x \\] <p>So:</p> <ul> <li>An up move corresponds to a log-return of \\(+\\sigma \\sqrt{\\Delta t}\\)</li> <li>A down move corresponds to a log-return of \\(-\\sigma \\sqrt{\\Delta t}\\)</li> </ul> <ul> <li>These returns are symmetric around 0</li> <li>They have variance \\(\\sigma^2 \\Delta t\\)</li> <li>Which is exactly what Geometric Brownian Motion assumes in the Black-Scholes model</li> </ul> <p>So this clever choice of \\(u = e^{\\sigma \\sqrt{\\Delta t}}, d = e^{-\\sigma \\sqrt{\\Delta t}}\\) ensures that the binomial model behaves like the continuous-time stochastic process when \\(\\Delta t \\to 0\\).</p>"},{"location":"Derivative%20Pricing/05-american-options/","title":"American Options","text":"<p>American options are different from the European options. American options allow the buyer to exercise the option at any point in time. This important characteristic has further derived implications in real markets: </p> <ul> <li>Flexibility to the buyer </li> <li>Risk to the seller </li> <li>Hedging (delta) exposure </li> <li>OTC vs.Exchange-traded </li> <li>Popularity </li> <li>High premiums ( options prices )</li> </ul>"},{"location":"Derivative%20Pricing/05-american-options/#binomial-mode-for-american-options","title":"Binomial Mode for American Options","text":"<p>In the binomial tree, we move backward in time just like for European options - but now, at each node we check:</p> \\[ \\text{Option Value }=max(\\text{ Hold Value},\\text{ Exercise Value}) \\] <p>That is :</p> <ul> <li>Hold value: discounted expected value from the two next steps<ul> <li>\\(\\text{Hold} = e^{-r \\Delta t} \\cdot \\left[ p \\cdot V_{t+1,i+1} + (1 - p) \\cdot V_{t+1,i} \\right]\\)</li> </ul> </li> <li>Exercise value: immediate payoff from exercising the option <ul> <li>Call: \\(max(S_{t,i} - K,0)\\)</li> <li>Put: \\(max(K - S_{t,i},0)\\)</li> </ul> </li> </ul> <p>Where American Option Value at node (t,i):</p> \\[ V_{t,i} = \\max \\left( \\text{Immediate Payoff},\\ \\text{Discounted Expected Future Value} \\right) \\] <p>When is early exercise not optimal ? </p> <p>For American call options on non-dividend-paying stocks:</p> <p>Never exercise early. Its better to hold. </p> <p>For American put options, early exercise sometimes are optimal. </p>"},{"location":"Derivative%20Pricing/05-american-options/#code","title":"Code","text":"<p>In <code>wqu</code> the American options is handled by the same class <code>BinomialTree</code> and can be used as:</p> Python<pre><code>from wqu.dp import BinomialTree\n\n\nbt_put_am = BinomialTree(S0=50, K=52, T=2, r=0.05, u=1.2, d=0.8, N=2, option_type='put', option_style='american')\nbt_put_am.build_stock_tree()\nbt_put_am.build_option_tree()\nbt_put_am.summary()\n\nbt_put_am.price()\n</code></pre> <p>Or </p> Python<pre><code>bt_call_am = BinomialTree(S0=50, K=52, T=2, r=0.05, u=1.2, d=0.8, N=2, option_type='call', option_style='american')\nbt_call_am.summary()\n\nbt_call_am.price()\n</code></pre> <p>Put-call parity for the American style call options also possible with:</p> Python<pre><code>bt_call_am.check_put_call_parity(verbose=True)\n</code></pre>"},{"location":"Derivative%20Pricing/05-american-options/#delta-hedging-for-american-style","title":"Delta hedging for American style","text":"<p>In Europian options, delta hedge is planned based on the final option payoff only and no early exercise means its easier to implement. However, in the American options, due to the fact that the option might be exercised early, the value ofthe option may not follow a smooth path like the European case. This makes hedging harder, more dynamic and potentially more expensive. </p> <p>Dynamic hedging means:</p> <ul> <li>Adjust the delta hedge step-by-step</li> <li>At every node in the binomial tree, recalculate \\(\\Delta\\)</li> <li>Buy/Sell stock to match the new delta.</li> </ul> <p>Delta is still: </p> \\[ \\Delta = \\frac{V_{\\text{up}} - V_{\\text{down}}}{S_{\\text{up}} - S_{\\text{down}}} \\] <p>for both American and European options, but: </p> <ul> <li>With American options, payoff can change earlier </li> <li>Hence the option value tree is different </li> <li>So delta tree is different </li> <li>So hedging strategy is different </li> </ul> <p>This can be done with the following code if using <code>wqu</code>:</p> Python<pre><code>from wqu.dp import BinomialTree\n\n\nbt_put_am = BinomialTree(S0=50, K=52, T=2, r=0.05, u=1.2, d=0.8, N=2, option_type='put', option_style='american')\nbt_put_am.build_stock_tree()\nbt_put_am.build_option_tree()\nbt_put_am.summary()\n\nbt_put_am.price()\n</code></pre> <p>We can also simulate a specic hedge path. </p> Python<pre><code>bt_am_put = BinomialTree(S0=50, K=52, T=2, r=0.05, u=1.2, d=0.8, N=2, option_type='put', option_style='american')\nbt_am_put.build_stock_tree()\nbt_am_put.build_option_tree()\nbt_am_put.build_delta_tree()\n\n# Simulate dynamic hedge for path: up then down\nbt_am_put.simulate_delta_hedge(path='ud')\n</code></pre> <p>which returns response similar to:</p> Text Only<pre><code>Initial Hedge:\nStock: 50.00, Delta: -0.53, Shares: -0.53, Cash: 26.46, Total: 0.00\n\nStep | Stock  | Delta  | Shares \u0394 | Stock Value | Cash | Total\n 1    | 60.00   | -0.17  | 0.36     | -10.00      | 8.33   | -1.67\n 2    | 48.00   | 0.00   | 0.17     | 0.00        | -1.67  | -1.67\n\nFinal Results:\n  Hedged Portfolio Value : -1.6667\n  Option Payoff          : 4.0000\n  Hedging Error          : -5.6667\n(np.float64(-1.6666666666666679),\n np.float64(4.0),\n np.float64(-5.666666666666668))\n</code></pre> <p>Why is the Hedging Error there ? </p> <p>This is expected. </p> <p>Dynamic delta hedging in discrete time is an approximation. We are only hedging once per time step, delta changes between time steps, but we can\u2019t react instantly. For American options, early exercise adds more complexity - hedge based on the value to hold, but the option may be exercised earlier. </p>"},{"location":"Derivative%20Pricing/06-asian-options/","title":"Asian Options","text":"<p>So far, we dealt with options where the payoff depends only on the final price of the stock:</p> <ul> <li>Call \\(max(S_T - K,0)\\)</li> <li>Put \\(max(K-S_T,0)\\)</li> </ul> <p>But path-dependent options are different. Their payoff depends on the entire path the stock price takes - not just the final value. </p> <p>Its like saying: \u201cI care not just about where you are now, but everywehre you\u2019ve been before you got here\u201d</p>"},{"location":"Derivative%20Pricing/06-asian-options/#examples-of-path-dependent-options","title":"Examples of Path-dependent options","text":"<ol> <li>Asian Option: Payoff depends on the average price of the underlying asset during the life of the option. <ol> <li>Asian Call: \\(max(\\bar S - K,0)\\)</li> <li>Asian Put: \\(max(K-\\bar S,0)\\)</li> </ol> </li> <li>Lookback Option: Payoff depends on the maximum or minimum stock price during the life of the operation. </li> <li>Barrier Option: Payoff activates only if a price hits a barrier at some point in time. </li> </ol>"},{"location":"Derivative%20Pricing/06-asian-options/#asian-option-with-binary-tree","title":"Asian Option with Binary Tree","text":"<p><code>wqu</code> supports building and checking the Asian (european style exercise only) with Python:</p> Python<pre><code>from wqu.dp import BinomialTree\n\n\nbt_asian = BinomialTree(\n    S0=100, K=95, T=1, r=0.05,\n    u=1.1, d=0.9, N=3,\n    option_type='call',\n    option_style='asian'\n)\n\nbt_asian.build_stock_tree()\nbt_asian.build_option_tree()\nprint(\"Asian Call Price:\", bt_asian.price())\n</code></pre>"},{"location":"Derivative%20Pricing/07-monte-carlo/","title":"Monter Carlo Methods in Option Pricing","text":"<p>Monte Carlo methods simulate randomness - to estimate values that are hard to compute exactly. \ud83c\udfb2 The core idea is to use random samples to estimate an expected value. </p> <p>Imagine you are estimating the average winnings of a dice game: </p> <p></p> <p>You can either:</p> <ul> <li>List every possible outcome (hard)</li> <li>Or simulate 10,000 rolls and compute the average (Monte Carlo Simulation)</li> </ul> <p>This works because of the Law of the Large Numbers</p> \\[ \\mathbb{E}[f(X)] \\approx \\frac{1}{M} \\sum_{i=1}^{M} f(X_i) \\] <p>Where: </p> <ul> <li>\\(X_i\\) are random samples from the distribution</li> <li>\\(M\\) is the number of simulations </li> <li>\\(f(X)\\) is the function we care about (e.g. option payoff)</li> </ul>"},{"location":"Derivative%20Pricing/07-monte-carlo/#monte-carlo-option-pricing-for-european-options-vanilla","title":"Monte Carlo Option Pricing for European Options (Vanilla)","text":"<p>Core concept: Monte Carlo simulates the many outcomes of the asset prices, compute the payoff for each, and average them. </p>"},{"location":"Derivative%20Pricing/07-monte-carlo/#price","title":"Price","text":"<p>We define: </p> <ul> <li>\\(S_0\\) the initial stock price </li> <li>\\(K\\) strike price </li> <li>\\(T\\) time to maturity </li> <li>r risk-free rate </li> <li>\\(\\sigma\\) volatelity </li> <li>\\(Z_i \\sim \\mathcal{N}(0,1)\\) standard normal random sample </li> </ul> <p>The we can simulate the terminal stock price as:</p> \\[ S_T^{(i)} = S_0 \\cdot \\exp\\left[\\left(r - \\frac{1}{2}\\sigma^2\\right)T + \\sigma \\sqrt{T} \\cdot Z_i\\right] \\] <p>This derived from the analytical solution of the geometric Brownian motion (Black-sholes model) </p>"},{"location":"Derivative%20Pricing/07-monte-carlo/#payoff","title":"Payoff","text":"<p>Then we compute the payoff:</p> <p>For a call \\(\\text{payoff}^{(i)} = \\max(S_T^{(i)} - K, 0)\\) or for a put \\(\\text{payoff}^{(i)} = \\max(K - S_T^{(i)}, 0)\\) </p>"},{"location":"Derivative%20Pricing/07-monte-carlo/#discount-and-average","title":"Discount and Average","text":"\\[ \\text{Price} = e^{-rT} \\cdot \\frac{1}{M} \\sum_{i=1}^{M} \\text{payoff}^{(i)} \\] <p>where \\(N\\) is the number of simulations. </p> <p>In summary : </p> <pre><code>graph TD\n    A[S0, K, T, r, sigma] --&gt; B[Generate M standard normals Z]\n    B --&gt; C[Simulate M terminal prices S_T]\n    C --&gt; D[Calculate M payoffs]\n    D --&gt; E[Discount each payoff]\n    E --&gt; F[Average \u2192 Option Price]</code></pre>"},{"location":"Derivative%20Pricing/07-monte-carlo/#monter-carlo-option-pricing-for-asian-options","title":"Monter Carlo Option Pricing for Asian Options","text":""},{"location":"Derivative%20Pricing/07-monte-carlo/#price-paths","title":"Price Paths","text":"<p>We define:</p> <ul> <li>\\(\\Delta t=\\frac{T}{N}\\)</li> <li>At each step: \\(S_{t+\\Delta t} = S_t \\cdot \\exp\\left[\\left(r - \\frac{1}{2}\\sigma^2\\right)\\Delta t + \\sigma \\sqrt{\\Delta t} \\cdot Z\\right]\\) </li> </ul> <p>Meaning for each step we need to repeat: </p> \\[ S_{t+\\Delta t} = S_t \\cdot \\exp\\left[\\left(r - \\frac{1}{2}\\sigma^2\\right)\\Delta t + \\sigma \\sqrt{\\Delta t} \\cdot Z\\right] \\] <p>then we get full path: \\([S_0, S_1, \u2026, S_T]\\)</p>"},{"location":"Derivative%20Pricing/07-monte-carlo/#average-stock-price","title":"Average Stock Price","text":"\\[ \\bar{S} = \\frac{1}{N+1} \\sum_{j=0}^{N} S_j \\]"},{"location":"Derivative%20Pricing/07-monte-carlo/#payoff_1","title":"Payoff","text":"<ul> <li>Call : \\(\\max(\\bar{S} - K, 0)\\) </li> <li>Put: \\(\\max(K - \\bar{S}, 0)\\) </li> </ul>"},{"location":"Derivative%20Pricing/07-monte-carlo/#discount-and-average_1","title":"Discount and Average","text":"\\[ \\text{AsianPrice} = e^{-rT} \\cdot \\frac{1}{M} \\sum_{i=1}^{M} \\text{payoff}^{(i)} \\] <p>Summary workflow: </p> <pre><code>graph TD\n    A[S0, K, T, r, sigma, N time steps, M paths] --&gt; B[Simulate M price paths with N steps]\n    B --&gt; C[Compute average price per path]\n    C --&gt; D[Calculate M payoffs]\n    D --&gt; E[Discount and average]\n    E --&gt; F[Asian Option Price]</code></pre>"},{"location":"Derivative%20Pricing/07-monte-carlo/#note","title":"Note","text":"<p>M and N are not the same thing in this context.</p> Symbol Meaning Typical Use M Number of Monte Carlo simulations How many paths you simulate N Number of time steps in each path How finely each path is discretized over time <ul> <li>M = number of \u201cstudents\u201d running through the simulation</li> <li>N = number of \u201ccheckpoints\u201d each student passes before the final test</li> </ul>"},{"location":"Derivative%20Pricing/07-monte-carlo/#monte-carlo-with-binomial","title":"Monte Carlo (with binomial )","text":""},{"location":"Derivative%20Pricing/07-monte-carlo/#timestep","title":"Timestep","text":"<p>get \\(dt = \\frac{T}{N}\\)</p> <p>where we calculate the time step. But it i not used to increment time in a loop, instead, its used to compute up/down factors and risk-neutral probabilities. </p>"},{"location":"Derivative%20Pricing/07-monte-carlo/#compute-u-d-p","title":"Compute u, d, p","text":"<p>These are binomial model components: </p> \\[ u = e^{\\sigma \\sqrt{dt}}, \\quad d = e^{-\\sigma \\sqrt{dt}}, \\quad p = \\frac{e^{r dt} - d}{u - d} \\] <p>So this is using binomial tree dynamics to simulate price movements.</p>"},{"location":"Derivative%20Pricing/07-monte-carlo/#for-each-path","title":"For Each Path:","text":"<p>Instead of Brownian motion (Z ~ N(0,1)), it samples from: <code>np.random.binomial(1, p, N + 1)</code> his produces a vector of ups (1) and downs (0) \u2192 exactly like in a binomial tree.</p> <p>Then it builds the full path using u and d.</p>"},{"location":"Derivative%20Pricing/07-monte-carlo/#final-payoff-only","title":"Final Payoff Only:","text":"\\[ C[j] = e^{-rT} \\cdot \\max(S_T - K, 0) \\] <p>So even though a path is generated, the final value is the only part used \u2014 like a European option. </p>"},{"location":"Derivative%20Pricing/07-monte-carlo/#code-implementation-and-example","title":"Code implementation and example","text":"<p>We can use either methods with the <code>wqu</code> package, like below: </p> Python<pre><code>from wqu.dp.montecarlo import MonteCarlo\n\nmc = MonteCarlo(S0=100, K=95, T=1, r=0.05, sigma=0.2, N=50, M=10000,\n                option_type='call', option_style='asian', method='binomial')\n\nprint(\"Asian Option (Binomial Monte Carlo):\", mc.price())\n\nmc_cont = MonteCarlo(S0=100, K=95, T=1, r=0.05, sigma=0.2, N=50, M=10000,\n                     option_type='call', option_style='asian', method='continuous')\n\nprint(\"Asian Option (Continuous Monte Carlo):\", mc_cont.price())\n</code></pre> Text Only<pre><code>Asian Option (Binomial Monte Carlo): 8.695634694961363\nAsian Option (Continuous Monte Carlo): 8.672993641680282\n</code></pre> Python<pre><code>from wqu.dp.montecarlo import MonteCarlo\n\nmc = MonteCarlo(S0=100, K=95, T=1, r=0.05, sigma=0.2, N=50, M=10000,\n                option_type='call', option_style='european', method='binomial')\n\nprint(\"Europian Option (Binomial Monte Carlo):\", mc.price())\n\nmc_cont = MonteCarlo(S0=100, K=95, T=1, r=0.05, sigma=0.2, N=50, M=10000,\n                     option_type='call', option_style='european', method='continuous')\n\nprint(\"Europian Option (Continuous Monte Carlo):\", mc_cont.price())\n</code></pre> Text Only<pre><code>Europian Option (Binomial Monte Carlo): 13.320182246971445\nEuropian Option (Continuous Monte Carlo): 13.280390336599178\n</code></pre> <p>We can also plot the convergence of price with M. </p> Python<pre><code>from wqu.dp.montecarlo import MonteCarlo\n\nmc = MonteCarlo(S0=100, K=95, T=1, r=0.05, sigma=0.2,\n                N=50, M=10000, option_type='call',\n                option_style='asian', method='continuous')\n\nmc.plot_convergence(M_values=[100, 500, 1000, 2500, 5000, 10000, 20000])\n</code></pre> <p></p> <p>or Even better with the setting the pseudo-random number generator used by NumPy (or any RNG) for reproducibility: </p> Python<pre><code>import numpy as np\nnp.random.seed(123)\nmc_asian = MonteCarlo(S0=100, K=90, T=1, r=0, sigma=0.3, N=2500, M=10000, option_style='asian', method='binomial')\nprint(mc_asian.price())\n</code></pre>"},{"location":"Derivative%20Pricing/08-markov-gbm/","title":"Markov property and GBM","text":""},{"location":"Derivative%20Pricing/08-markov-gbm/#stochastic-proceses","title":"Stochastic proceses","text":"<p>imagine you\u2019re watching the stock price of a company go up and down like a leaf in the wind. It seems random. A stochastic process is just a fancy name for something that changes over time in a random way. </p>"},{"location":"Derivative%20Pricing/08-markov-gbm/#markov-process","title":"Markov Process","text":"<p>In intuition, the markov process means: \u201cWhat happens next depends only on what\u2019s happening now, not on how we got here.\u201d So we say, that If its sunday today and tomorrow\u2019s weather depends only on today (not on the past week), that\u2019s markov process. </p> <p>This is great for stock prices -traders say \u201ceverything the market knows is already in the price\u201d</p>"},{"location":"Derivative%20Pricing/08-markov-gbm/#brownian-motion","title":"Brownian Motion","text":"<p>Imagine the dust particles dancing under a microscope - totally random motion. Mathematically, this idea is called Brownian motion, or a Wiener Process. </p> <p>It has two key rules:</p> <ol> <li>Each change is random. \\(\\Delta z = \\varepsilon \\sqrt{\\Delta t}, \\quad \\varepsilon \\sim \\mathcal{N}(0, 1)\\)</li> <li>Each step is independent from the previous ones (like a drunk guy forgetting where he walked before)</li> </ol> <p>We want to model stock price that:</p> <ol> <li>Grows over time (hopefully) -&gt; drift </li> <li>Is uncertain/random -&gt; volatility </li> </ol> <p>We combine both: </p> \\[ ds = \\mu Sdt + \\sigma SdW_t \\] <p>Where:</p> <ul> <li>\\(S\\)  = current stock price </li> <li>\\(\\mu\\) = average/expected return (drift)</li> <li>\\(\\sigma\\) = volatility </li> <li>\\(dW_t\\) = Wiener process = \\(\\epsilon \\sqrt{dt}\\)</li> </ul> <p>This is the famous Geometric Brownian Motion (GBM)</p> <pre><code>flowchart TD\n    A[Start: Stock Price S\u2080] --&gt; B[Add Drift: \u03bc S dt]\n    A --&gt; C[Add Randomness: \u03c3 S dW\u209c]\n    B --&gt; D[Combine changes: dS = \u03bcS dt + \u03c3S dW\u209c]\n    C --&gt; D\n    D --&gt; E[New Price: S\u2081 = S\u2080 + dS]\n    E --&gt; F[Repeat over time for S\u2082, S\u2083, ...]</code></pre>"},{"location":"Derivative%20Pricing/08-markov-gbm/#gbm-geometric-brownian-motion","title":"GBM (Geometric Brownian Motion)","text":"<p>Geometric Brownian Motion (GBM) is a model - a mathematical method - to simulate or describe how stock prices evolve over time. More precisly GBM is the standard model used in finance to describe the continuous-time dynamics of asset prices like stocks. </p> <p>The GBM formula (Stochastic Differential Equation SDE)</p> \\[ dS = \\mu S \\,dt + \\sigma S \\,dW_t \\] <p>Where:</p> <ul> <li>\\(S\\) = stock price at time t</li> <li>\\(\\mu\\) = expected return (drift)</li> <li>\\(\\sigma\\) = volatility</li> <li>\\(dW_t\\) = Brownian motion = random noise</li> </ul> <p>Interpretation:</p> <ul> <li>The term \\(\\mu S dt\\): deterministic growth \u2192 like compound interest</li> <li>The term \\(\\sigma S dW_t\\): randomness or noise \u2192 price jumps, news, volatility</li> </ul>"},{"location":"Derivative%20Pricing/08-markov-gbm/#get-gmb-in-practice","title":"Get GMB in practice","text":"<p>There are mainly two ways to get GMB in practice:</p>"},{"location":"Derivative%20Pricing/08-markov-gbm/#exact-solution-analytical-formula","title":"Exact Solution (Analytical Formula)","text":"<p>This uses the exact mathematical solution of the GBM differential equation: </p> \\[ dS = \\mu S \\, dt + \\sigma S \\, dW_t \\] <p>Solving it using It\u00f4 calculus, we get the closed-form solution:</p> \\[ S_t = S_0 \\cdot \\exp\\left[\\left(\\mu - \\frac{1}{2} \\sigma^2\\right)t + \\sigma W_t\\right] \\] <ul> <li>Advantage: Precise, fast, and numerically stable.</li> <li>Used in: Black-Scholes model, pricing options, simulations with fixed time steps.</li> </ul> <p>Think of W_t like a random seed in a game:</p> <ul> <li>You don\u2019t know in advance what path you\u2019ll take,</li> <li>But once the seed is fixed, the entire path is precisely determined.</li> </ul> <p>So each realization of S_t is different (because each path of W_t is different),</p> <p>but the equation for generating that path is exact and correct.</p> <p>If we take logs:</p> \\[ \\ln S_t = \\ln S_0 + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t + \\sigma W_t \\] <p>This shows that the log-price follows a normal distribution. That\u2019s why GBM implies log-normal prices.</p> Python<pre><code>S[i+1] = S[i] + mu * S[i] * dt + sigma * S[i] * np.sqrt(dt) * np.random.randn()\n</code></pre>"},{"location":"Derivative%20Pricing/08-markov-gbm/#euler-simulation-euler-maruyama-approximation","title":"Euler Simulation (Euler-Maruyama Approximation)","text":"<p>Instead of solving the equation, you approximate it step-by-step:</p> \\[ S_{t + \\Delta t} \\approx S_t + \\mu S_t \\Delta t + \\sigma S_t \\sqrt{\\Delta t} \\cdot \\varepsilon \\] <p>Where \\(\\varepsilon \\sim \\mathcal{N}(0,1)\\)</p> <p>This gives you an iterative simulation of the price path.</p> <ul> <li>Advantage: Intuitive, flexible, can be used with more complex models.</li> <li>Used in: Monte Carlo simulations, multi-asset models, SDEs with no closed form.</li> </ul> <p>The Euler-Maruyama method is a numerical approximation of the solution to a stochastic differential equation (SDE).</p> <p>It doesn\u2019t solve the equation exactly like we did with the closed-form GBM formula, but it simulates it step by step, over small time intervals.</p> <ul> <li>We start from the SDE again: \\(dS_t = \\mu S_t \\, dt + \\sigma S_t \\, dW_t\\) </li> <li>Euler approximation (discrete version): \\(S_{t+\\Delta t} = S_t + \\mu S_t \\, \\Delta t + \\sigma S_t \\, \\sqrt{\\Delta t} \\cdot \\varepsilon \\quad\\text{where } \\varepsilon \\sim \\mathcal{N}(0, 1)\\) </li> <li>\\(\\mu S_t \\, dt\\) is the deterministic part (drift)</li> <li>\\(\\sigma S_t \\, dW_t \\approx \\sigma S_t \\, \\sqrt{dt} \\cdot \\varepsilon\\) is the noise</li> <li>We iterate over time using a for-loop:</li> </ul> Python<pre><code>for i in range(1, N):\n    S[i] = S[i-1] + mu * S[i-1] * dt + sigma * S[i-1] * np.sqrt(dt) * np.random.randn()\n</code></pre>"},{"location":"Derivative%20Pricing/08-markov-gbm/#python","title":"Python","text":"<p><code>wqu</code> package includes python methods for both of the above. </p> Python<pre><code>from wqu.dp import GBM\n\n# Create a GBM simulator\ngbm = GBM(S0=100, mu=0.05, sigma=0.2, T=1, N=252, seed=42)\n\n# Simulate one exact path and print first 5 prices\npath = gbm.simulate(method=\"exact\")\nprint(path[:5])\n\n# Plot a single Euler path\ngbm.plot(M=1, method=\"euler\", color='green', lw=2)\n\n# Plot 100 Monte Carlo paths using exact GBM\ngbm.plot(M=100, method=\"exact\", alpha=0.2)\n</code></pre> <p></p> <p></p>"},{"location":"Derivative%20Pricing/09-black-scholes/","title":"Ito\u2019s Lemma and Black-Scholes Model","text":""},{"location":"Derivative%20Pricing/09-black-scholes/#stock-prices-are-log-normally-why","title":"Stock prices are Log-Normally \u2013 Why ?","text":"<p>Real-world intuition:</p> <p>Prices can not go negative. But returns (i.e., the percentage change in price) can. That\u2019s why we assume: </p> <ul> <li>Log of the stock price (returns) follows a normal distribution</li> <li>So the stock price itself is log-normal </li> </ul> \\[ \\ln S_t = \\ln S_0 + \\left( \\mu - \\frac{1}{2} \\sigma^2 \\right)t + \\sigma W_t \\Rightarrow S_t = S_0 \\cdot e^{\\left( \\mu - \\frac{1}{2} \\sigma^2 \\right)t + \\sigma W_t} \\] <p>This means:</p> <ul> <li>\\(\\ln S_t \\sim \\mathcal{N}(\\text{mean}, \\text{variance})\\)</li> <li>\\(S_t \\sim \\text{Log-Normal}\\)</li> </ul>"},{"location":"Derivative%20Pricing/09-black-scholes/#itos-lemma-the-chain-rule-for-randomness","title":"It\u00f4\u2019s Lemma \u2014 The Chain Rule for Randomness","text":"<p>If: \\(dS = \\mu S dt + \\sigma S dW\\) And we want to know how a function of S (like \\ln S or an option) evolves, we can\u2019t use normal calculus. We use It\u00f4\u2019s Lemma, which accounts for the \u201cwiggle\u201d of Brownian motion. </p> <p>It\u00f4\u2019s Lemma (1D case)</p> <p>Let \\(f(S, t)\\) be a function. If \\(dS = \\mu S dt + \\sigma S dW\\), then:</p> \\[ df = \\frac{\\partial f}{\\partial t} dt + \\frac{\\partial f}{\\partial S} dS + \\frac{1}{2} \\frac{\\partial^2 f}{\\partial S^2} \\sigma^2 S^2 dt \\] <p>Apply It\u00f4\u2019s Lemma to \\(f(S) = \\ln S\\)</p> <p>If we apply It\u00f4\u2019s Lemma to \\(\\ln S\\), we get: </p> \\[ d(\\ln S) = \\left( \\mu - \\frac{1}{2} \\sigma^2 \\right) dt + \\sigma dW \\] <p>Integrate both sides \u21d2 the formula we saw earlier for log-normal stock prices. </p>"},{"location":"Derivative%20Pricing/09-black-scholes/#black-sholes-equation","title":"Black-Sholes Equation","text":"<p>Imagine creating a risk-free portfolio by combining:</p> <ul> <li>A long/short position in the stock</li> <li>A derivative (like a call or put)</li> </ul> <p>Apply no-arbitrage and risk-neutral logic, you arrive at the Black-Scholes PDE:</p> \\[ \\frac{\\partial f}{\\partial t}     \u2022   rS \\frac{\\partial f}{\\partial S}     \u2022   \\frac{1}{2} \\sigma^2 S^2 \\frac{\\partial^2 f}{\\partial S^2} = rf \\]"},{"location":"Derivative%20Pricing/09-black-scholes/#black-scholes-formula-for-option-prices","title":"Black-Scholes Formula for Option Prices","text":""},{"location":"Derivative%20Pricing/09-black-scholes/#call-option","title":"Call Option:","text":"\\[ c = S_0 N(d_1) - Ke^{-rT} N(d_2) \\]"},{"location":"Derivative%20Pricing/09-black-scholes/#put-option","title":"Put Option:","text":"\\[ p = Ke^{-rT} N(-d_2) - S_0 N(-d_1) \\] <p>Where:</p> \\[ d_1 = \\frac{\\ln(S_0 / K) + (r + \\frac{1}{2} \\sigma^2)T}{\\sigma \\sqrt{T}}, \\quad d_2 = d_1 - \\sigma \\sqrt{T} \\] <p>\\(N(x)\\) = cumulative distribution function of standard normal</p>"},{"location":"Derivative%20Pricing/09-black-scholes/#greeks-sensitivities","title":"Greeks (Sensitivities)","text":"Greek Meaning Formula (Call) Delta Sensitivity to price \\(\\Delta = N(d_1)\\) Gamma Sensitivity of Delta to price \\(\\Gamma = \\frac{N{\\prime}(d_1)}{S\\sigma\\sqrt{T}}\\) Vega Sensitivity to volatility \\(\\nu = S N{\\prime}(d_1) \\sqrt{T}\\) Theta Sensitivity to time (complex, depends on call/put) Rho Sensitivity to interest rate \\(\\rho = K(T) e^{-rT} N(d_2)\\)"},{"location":"Derivative%20Pricing/09-black-scholes/#python","title":"Python","text":"Python<pre><code>from wqu.dp import BlackScholes\n\n# Example: A call option\nbs = BlackScholes(S0=100, K=100, T=1, r=0.05, sigma=0.2, option_type=\"call\")\n\nprint(\"Option Price:\", bs.price())\nprint(\"Delta:\", bs.delta())\nprint(\"Gamma:\", bs.gamma())\nprint(\"Vega:\", bs.vega())\nprint(\"Theta:\", bs.theta())\nprint(\"Rho:\", bs.rho())\n</code></pre> Text Only<pre><code>Option Price: 10.450583572185565\nDelta: 0.6368306511756191\nGamma: 0.018762017345846895\nVega: 37.52403469169379\nTheta: -6.414027546438197\nRho: 53.232481545376345\n</code></pre> <p>or</p> Python<pre><code>bs = BlackScholes(S0=100, K=76, T=1, r=0.05, sigma=0.2, option_type=\"put\")\nprint(bs.to_dict())\n\nbs.plot_greeks(S_range=(80, 120))\n</code></pre> <p></p> <p>With simulation:</p> Python<pre><code># With MonteCarlo \n# bs_call_mc(100, 95, 0.06, 0.3, 1, 0, 100000)) \n\nfrom wqu.dp.montecarlo import MonteCarlo\n\nmc = MonteCarlo(\n    S0=100, K=95, T=1, r=0.06, sigma=0.3,\n    N=1, M=100000,  # N=1 since it's a single-step terminal price\n    option_type='call',\n    option_style='european',\n    method='continuous'\n)\n\nprint(\"Monte Carlo Price:\", mc.price())\n</code></pre> Python<pre><code>from wqu.dp.black_scholes import BlackScholes\n\n# bs_call_price(100, 0.06, 0.3, 0, 1, 95))\nbs = BlackScholes(S0=100, K=95, T=1, r=0.06, sigma=0.3, option_type=\"call\")\nprint(\"BS Analytical Price:\", bs.price())\n</code></pre>"},{"location":"Derivative%20Pricing/10-vasicek/","title":"Vasicek Interest Rate Model","text":""},{"location":"Derivative%20Pricing/10-vasicek/#tldr","title":"TL;DR","text":"<p>The Vasicek model simulates interest rates that bounce around a long-term average.It uses a mean-reverting SDE where randomness and pull-back forces combine.We simulate it using a simple time-stepping method like we did with GBM.</p> <p>Vasicek model is a mathematical model used to describe how interest rates change over time. </p> <p>Key idea: Mean Reversion - Interest rates don\u2019t just wander aimlessly, they tend to go back toward some long-term average ( like gravity pulling them in).</p> <p>The SDE (Stochastic Differential Equation):</p> \\[ dr_t = k(\\theta - r_t)dt + \\sigma dZ_t \\] <p>Where:</p> <ul> <li>\\(r_t\\) interest rate at time t </li> <li>\\(\\theta\\) long term average interest rate (mean level)</li> <li>\\(k\\): speed of mean reversion (how fast we go back to \\(\\theta\\))</li> <li>\\(\\sigma\\): volatility (how much randomness per unit time)</li> <li>\\(dZ_t\\): standard Brownian motion (random noise)</li> </ul> <p>Intuition Behind the formula </p> <ul> <li>If current rate \\(r_t &lt; \\theta\\), the drift \\(k(\\theta - r_t) &gt; 0\\) \u2192 rate increases</li> <li>If \\(r_t &gt; \\theta\\), then \\(k(\\theta - r_t) &lt; 0\\) \u2192 rate drops</li> <li>So the rate always tries to pull back toward \\(\\theta\\) over time</li> </ul> <p>How do we simulate it ?</p> <p>To simulate this using MonteCarlo:</p> <ol> <li>Discretize time into steps of \\(\\Delta t\\)</li> <li>Use this recurrence formula: \\(r_{t+1} = r_t + k(\\theta - r_t)\\Delta t + \\sigma \\sqrt{\\Delta t} \\cdot \\varepsilon\\) </li> <li>where \\(\\varepsilon \\sim \\mathcal{N}(0, 1)\\)</li> </ol> <p>This is the Euler discretization of the Vasicek process. </p> <p>Long-Run behavior</p> <ul> <li>Long term mean = \\(\\theta\\) </li> <li>Long term variance = \\(\\frac{\\sigma ^2}{2k}\\)</li> </ul> <p>So we get interest rate paths that wiggle, but hover around the mean \\(\\theta\\). </p>"},{"location":"Derivative%20Pricing/10-vasicek/#python","title":"Python","text":"Python<pre><code>from wqu.dp import Vasicek\n\n# Instantiate model\nvas = Vasicek(r0=0.03, k=0.15, theta=0.05, sigma=0.01, seed=42)\n\n# Plot a single path\nvas.plot(M=1, color='blue')\n\n# Plot multiple paths\nvas.plot(M=10, alpha=0.3)\n\n# Compare how 'theta' affects the mean reversion level\nvas.compare_parameters('theta', [0.03, 0.05, 0.07])\n</code></pre> Python<pre><code>from wqu.dp.vasicek import Vasicek\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Parameters\nM = 100\nN = 100\nT = 1.0\nr0 = 0.01875\nK = 0.20\ntheta = 0.01\nsigma = 0.012\n\n# Time grid\nt = np.linspace(0, T, N + 1)\n\n# Create and simulate\nvas = Vasicek(r0=r0, k=K, theta=theta, sigma=sigma, T=T, N=N, seed=42)\npaths = vas.simulate(M)  # shape (M, N+1)\n\n# Plot each path\nplt.figure(figsize=(10, 5))\nfor j in range(M):\n    plt.plot(t, paths[j])\n\nplt.xlabel(\"Time $t$\", fontsize=14)\nplt.ylabel(\"$r(t)$\", fontsize=14)\nplt.title(\"Vasicek Paths\", fontsize=14)\naxes = plt.gca()\naxes.set_xlim([0, T])\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"Derivative%20Pricing/11-returns/","title":"Stock returns","text":""},{"location":"Derivative%20Pricing/11-returns/#simple-returns","title":"Simple Returns","text":"<p>If a stock goes from $100 to $110: </p> \\[ R_t = \\frac{P_t - P_{t-1}}{P_{t-1}} = \\frac{110 - 100}{100} = 0.10 = 10\\% \\] <p>Easy to interpret, additive over time frames.</p>"},{"location":"Derivative%20Pricing/11-returns/#continuously-compounded-returns-log-returns","title":"Continuously Compounded Returns (Log Returns)","text":"\\[ r_t = \\ln \\left( \\frac{P_t}{P_{t-1}} \\right) \\] <p>Why log returns?</p> <ul> <li>More mathematically elegant</li> <li>Additive across time</li> <li>Preferred in models like GBM and Black-Scholes</li> </ul>"},{"location":"Derivative%20Pricing/11-returns/#annualized-returns","title":"Annualized Returns","text":"<p>We often want to scale returns to a yearly basis.  (Assuming 252 trading days in a year)</p> <ul> <li>For simple daily returns: \\(R_{\\text{annual}} = (1 + \\bar{R}_{\\text{daily}})^{252} - 1\\)  (Compounds returns over time. Uses geometric growth.)</li> <li>For log returns: \\(r_{\\text{annual}} = 252 \\cdot \\bar{r}_{\\text{daily}}\\)  (Adds returns over time. Uses arithmetic approximation.)</li> </ul> <p>When returns are small and volatility is low, log \u2248 simple.</p> <p>But as returns and volatility grow:</p> <ul> <li>Log returns underestimate performance</li> <li>Simple returns capture compounding effects</li> </ul>"},{"location":"Derivative%20Pricing/11-returns/#working-with-apis","title":"Working with APIs","text":"<p>To get real stock data (like prices of AAPL or SPY), we use financial data APIs, e.g.:     \u2022   Yahoo Finance (via yfinance)     \u2022   Alpha Vantage     \u2022   Polygon.io     \u2022   Quandl </p>"},{"location":"Derivative%20Pricing/11-returns/#characteristics-of-the-returns","title":"Characteristics of the Returns","text":"<p>Do real-world stock returns behave like the normal distribution (bell curve) ? Mostly models (like Black-Scholes, GBM, etc.) assume: \\(r_t \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) but is that assumption actually valid ?</p> <p>These are empirical truths observed from real market data \u2014 patterns that keep showing up: </p> <ul> <li>Returns are not normally distributed. <ul> <li>They have fat tails (more extreme events than a normal distribution would predict)</li> <li>They are leptokurtic (higher peaks and fatter tails)</li> </ul> </li> <li>Negative Skew<ul> <li>Big drops happen more than big gains </li> <li>The distribution is often tilted left </li> </ul> </li> <li>Volatility Clustering<ul> <li>High volatility periods tend to follow each other </li> <li>This violates the i.i.d. assumption of many models </li> </ul> </li> </ul>"},{"location":"Derivative%20Pricing/11-returns/#test-for-normality","title":"Test for normality","text":"<p>Jarque-Bera Test</p> <p>A test that checks whether skewness and kurtosis deviate from those of a normal distribution. </p> \\[ \\text{JB} = \\frac{n}{6} \\left( S^2 + \\frac{(K - 3)^2}{4} \\right) \\] <p>Where:</p> <ul> <li>n = number of observations</li> <li>S = skewness</li> <li>K = kurtosis </li> </ul> <p>If JB is large and p-value is small, we reject the normality assumption. </p> <p>If stock returns aren\u2019t normal:</p> <ul> <li>Models like Black-Scholes may underestimate extreme events (like crashes)</li> <li>We may need more advanced models (e.g., jump-diffusion, GARCH, heavy-tailed distributions)</li> </ul>"},{"location":"Derivative%20Pricing/11-returns/#correlated-returns","title":"Correlated Returns","text":"<p>In many real-world scenarios, we deal with multiple stocks, not just one. For example:</p> <ul> <li>Basket options depends on several assets </li> <li>Portfolio risk (VaR) requires simulating a group of stocks </li> <li>Stocks in the same industry or index are not independent </li> </ul> <p>So we want to simulate their prices, but also respect their correlations. </p>"},{"location":"Derivative%20Pricing/11-returns/#gbm-for-one-single-stock","title":"GBM for one single stock","text":"<p>We simulate prices using: \\(dS_t = \\mu S_t dt + \\sigma S_t dW_t\\) , Or in discrete form: \\(S_{t+1} = S_t \\cdot \\exp\\left((\\mu - \\frac{1}{2}\\sigma^2)\\Delta t + \\sigma \\sqrt{\\Delta t} \\cdot \\varepsilon_t \\right)\\) where \\(\\varepsilon_t \\sim N(0,1)\\). If we simulate two stocks this way using independent \\(\\varepsilon\\), they\u2019ll be uncorrelated. But real stock returns are correlated (e.g., Apple and Microsoft move similarly).</p>"},{"location":"Derivative%20Pricing/11-returns/#cholesky-decomposition","title":"Cholesky Decomposition","text":"<p>To simulate correlated random shocks \\(\\varepsilon_1, \\varepsilon_2\\), we can use:  Cholesky Decomposition</p> <ol> <li> <p>Let \\(\\Sigma\\) be your correlation matrix (e.g., from historical returns)</p> </li> <li> <p>Compute the Cholesky factor: \\(L \\text{ such that } \\Sigma = L L^\\top\\) </p> </li> <li>Generate independent \\(z \\sim \\mathcal{N}(0, I)\\) </li> <li>Create correlated values: \\(\\varepsilon = L z\\) </li> </ol> <p>This guarantees that the resulting \\(\\varepsilon\\) values have the desired correlation.</p> <p>We use Cholesky decomposition to simulate multiple stocks whose random price changes are correlated. Instead of sampling independent normal variables, we sample correlated ones using: \\(\\varepsilon = Lz, \\quad \\text{where } LL^\\top = \\Sigma\\) </p>"},{"location":"Derivative%20Pricing/11-returns/#coding","title":"Coding","text":"Python<pre><code>from wqu.dp import Returns\n\n# Create a stock return analyzer\napple = Returns(\"AAPL\", start=\"2022-01-01\")\n\n# Plot price history\napple.plot_price()\n\n# Plot log returns\napple.plot_returns(method=\"log\")\n\n# Annualized return\nprint(\"Annualized Log Return:\", apple.annualized_return(method=\"log\"))\nprint(\"Annualized Simple Return:\", apple.annualized_return(method=\"simple\"))\n</code></pre> Python<pre><code>Annualized Log Return: Ticker\nAAPL    0.037431\ndtype: float64\nAnnualized Simple Return: Ticker\nAAPL    0.083985\ndtype: float64\n</code></pre> Python<pre><code>apple = Returns(\"AAPL\", start=\"2022-01-01\")\n\n# Cumulative log return plot\napple.plot_cumulative_return(method=\"log\")\n\n# Cumulative simple return plot\napple.plot_cumulative_return(method=\"simple\")\n</code></pre> Python<pre><code>total_return = apple.cumulative_return(method=\"log\", as_series=False)\nprint(f\"Total return over the period: {total_return:.2%}\")\n</code></pre> Text Only<pre><code>Total return over the period: 13.00%\n</code></pre> Python<pre><code># Full summary\nfrom pprint import pprint\npprint(apple.summary(method=\"log\"))\n</code></pre> Python<pre><code>{'annualized_return': 0.03743128332933439,\n 'average_daily_return': 0.0001485368386084698,\n 'end_date': '2025-04-15',\n 'final_price': 202.13999938964844,\n 'start_date': '2022-01-03',\n 'ticker': 'AAPL',\n 'total_return': 0.13003185000794049,\n 'volatility_annual': 0.29385309739549303,\n 'volatility_daily': 0.018511005183202773}\n</code></pre> Python<pre><code>from pprint import pprint\n\napple = Returns(\"AAPL\", start=\"2022-01-01\")\n\n# Full stats\npprint(apple.summary(method=\"log\"))\n\n# Histogram\napple.plot_histogram()\n\n# Real vs Normal\napple.compare_with_normal()\n</code></pre> Text Only<pre><code>{'annualized_return': 0.037431283329334854,\n 'average_daily_return': 0.00014853683860847165,\n 'end_date': '2025-04-15',\n 'final_price': 202.13999938964844,\n 'jarque_bera_p': 1.5079435967188569e-307,\n 'jarque_bera_stat': 1412.9657533659843,\n 'kurtosis': 6.388733674088982,\n 'skewness': 0.3116206222444215,\n 'start_date': '2022-01-03',\n 'ticker': 'AAPL',\n 'total_return': 0.13003185000794226,\n 'volatility_annual': 0.2938530771694982,\n 'volatility_daily': 0.01851100390908486}\n</code></pre> Python<pre><code>multi = Returns(tickers=[\"AAPL\", \"MSFT\", \"GOOG\"], start=\"2022-01-01\")\nmulti.plot_returns()\npprint(multi.summary())\n</code></pre> JSON<pre><code>{'AAPL': {'annualized_return': 0.03743128332933385,\n          'average_daily_return': 0.00014853683860846764,\n          'end_date': '2025-04-15',\n          'final_price': 202.13999938964844,\n          'jarque_bera_p': 1.5058893297318933e-307,\n          'jarque_bera_stat': 1412.9684798174567,\n          'kurtosis': 6.388739786712888,\n          'skewness': 0.3116211853517522,\n          'start_date': '2022-01-03',\n          'total_return': 0.1300318500079385,\n          'volatility_annual': 0.2938530289858372,\n          'volatility_daily': 0.018511000873799522},\n 'GOOG': {'annualized_return': 0.028895018225221582,\n          'average_daily_return': 0.00011466277073500627,\n          'end_date': '2025-04-15',\n          'final_price': 158.67999267578125,\n          'jarque_bera_p': 6.480725439193935e-62,\n          'jarque_bera_stat': 281.7828866220795,\n          'kurtosis': 2.857321584240662,\n          'skewness': -0.11505899180745548,\n          'start_date': '2022-01-03',\n          'total_return': 0.0989634972040998,\n          'volatility_annual': 0.33268847483008585,\n          'volatility_daily': 0.020957404010899492},\n 'MSFT': {'annualized_return': 0.05185782809416014,\n          'average_daily_return': 0.0002057850321196831,\n          'end_date': '2025-04-15',\n          'final_price': 385.7300109863281,\n          'jarque_bera_p': 1.0016216603866884e-53,\n          'jarque_bera_stat': 244.07077916353825,\n          'kurtosis': 2.663900517276484,\n          'skewness': 0.07267980584196587,\n          'start_date': '2022-01-03',\n          'total_return': 0.18454777992431826,\n          'volatility_annual': 0.27965063119298217,\n          'volatility_daily': 0.01761633390759221}}\n</code></pre> Python<pre><code># For multiple tickers\nmulti = Returns(tickers=[\"AAPL\", \"MSFT\", \"GOOG\"], start=\"2022-01-01\")\n\n# Heatmap\nmulti.plot_correlation_heatmap()\n\n# Simulate correlated returns (like a Monte Carlo engine)\nsimulated = multi.simulate_correlated_returns(n_days=252)\nprint(simulated.head())\n\n# plot one simulated ticker\nsimulated[\"AAPL\"].cumsum().plot(title=\"Simulated AAPL Path\", figsize=(10, 4))\n</code></pre> Text Only<pre><code>                AAPL      MSFT      GOOG\n2025-04-16  0.010525  0.003827  0.012896\n2025-04-17  0.032033  0.014188  0.014764\n2025-04-18  0.033211  0.029396  0.018340\n2025-04-21  0.011485 -0.000376 -0.001103\n2025-04-22  0.005186 -0.024903 -0.027260\n</code></pre>"},{"location":"FAQs/other/","title":"Other common issues","text":""},{"location":"FAQs/other/#modulenotfounderror-no-module-named-pca","title":"ModuleNotFoundError: No module named 'pca\u2019","text":"<p>Current Python environment dose not have the <code>pca</code> PyPI package, we need to install it ( before other cells)</p> Python<pre><code>%%capture pca\n!pip install pca\n</code></pre>"},{"location":"FAQs/other/#modulenotfounderror-no-module-named-pandas_datareader","title":"ModuleNotFoundError: No module named 'pandas_datareader\u2019","text":"<p>same as above, you need to install this package with:</p> Python<pre><code>%%capture pdr\n!pip install pandas_datareader\n</code></pre>"},{"location":"FAQs/other/#modulenotfounderror-no-module-named-openpyxl","title":"ModuleNotFoundError: No module named 'openpyxl\u2019","text":"Python<pre><code>%%capture openpyxl\n!pip install openpyxl\n</code></pre>"},{"location":"FAQs/other/#filenotfounderror-pdread_csvdatamlfac_datcsv","title":"FileNotFoundError <code>pd.read_csv(\"../../data/mlfac_dat.csv\")</code>","text":"<p>This is happening because the environment dose not have the file in the path directed above. We need to download the data file from the GitHub, convert the R datafile into a csv file that Python can handle. </p> <p>The Colab notebook below has all the instructions and creates the correct CSV file: </p> <p></p> <p>Link to Colab: https://colab.research.google.com/drive/1HMvdd9LCvYjrWP5Pa2b0fn6HaWSsFcq7?usp=sharing </p>"},{"location":"FAQs/other/#modulenotfounderror-no-module-named-xgboost","title":"ModuleNotFoundError: No module named 'xgboost\u2019","text":"Python<pre><code>%%capture xgboost\n!pip install xgboost\n</code></pre>"},{"location":"FAQs/yfinance/","title":"Common <code>yfinance</code> related issues on the WQU Jupyter Notebooks and prefered solutions","text":""},{"location":"FAQs/yfinance/#nameerror-name-yf-is-not-defined","title":"NameError: name 'yf' is not defined","text":"<p>Maybe due to an initial environment setup, the WQU Jupyter notebooks may not have the <code>yfinance</code> library pre-installed, so the way to solve this is easy, you just need to install the package with the following (before any other code cells or before importing yfinance): </p> Python<pre><code>%%capture yfinance\n!pip install yfinance\n</code></pre> <p>Notice that we added <code>%%capture yfinance</code> in the first line. Which is to capture the code cell execution output ( we do not care about the installation details, we just want to have the yfinance)</p>"},{"location":"FAQs/yfinance/#keyerror-adj-close-not-in-index","title":"KeyError: \"['Adj Close'] not in index\u201d","text":"<p>This is due to the feature update on the latest version of <code>yfinance</code> , which auto-adjusts the Close prices based on the dividends so there is no need for the 'Adj Close' column, however, the WQU Jupyter notebooks seem to be written in 2022, with earlier versions of the yfinance package, so we have to revert back to the legacy behaviour of the <code>yfinance</code> :</p> <p>change your function call to download OHLCV from:</p> Python<pre><code>forex_data31 = yf.download(\"USDINR=X\", start=\"2019-01-02\", end=\"2022-06-30\")\nforex_data31 = forex_data31.reset_index()\ninr_df = forex_data31[[\"Date\", \"Adj Close\"]]\ninr_df.rename(columns={\"Adj Close\": \"inr\"}, inplace=True)\n</code></pre> <p>to:</p> Python<pre><code>forex_data31 = yf.download(\"USDINR=X\", start=\"2019-01-02\", end=\"2022-06-30\", auto_adjust=False)\nforex_data31 = forex_data31.reset_index()\ninr_df = forex_data31[[\"Date\", \"Adj Close\"]]\ninr_df.rename(columns={\"Adj Close\": \"inr\"}, inplace=True)\n</code></pre> <p>Notice the <code>auto_adjust=False</code>, which is the key change and it bring us the 'Adj Close' back.</p>"},{"location":"Stochastic%20Modeling/01-index/","title":"Stochastic Modeling","text":"<p>Stochastic modeling is a statistical approach that incorporates random variables to analyze and predict the behavior of complex systems. It used to model processes that involves undercetainty of randomness, such as a financial markets, weather patterns, or biological systems. </p>"},{"location":"Stochastic%20Modeling/01-index/#tddr","title":"TD;DR","text":"<p>Stochastic modeling is a mathematical approach used to predict and analyze systems or processes that involve inherent randomness and uncertainty. Unlike deterministic models, which yield the same outcome for a given set of inputs, stochastic models incorporate random variables, resulting in a range of possible outcomes, each with an associated probability. </p>"},{"location":"Stochastic%20Modeling/01-index/#key-characteristics","title":"Key characteristics","text":"<ul> <li>Incorporates Randomness: Stochastic models use random variables to reflect the uncertainty and variability present in real-world systems. </li> <li>Probability Distributions: The outcomes are described by probability distributions, which quantify the likelihood of different scenarios. </li> <li>Multiple Outcomes: Running the model multiple times with varying random inputs produces a spectrum of possible results, not just a single prediction. </li> <li>Scenario Simulation: These models enable simulation of various scenarios, helping users understand the range and probability of potential outcomes. </li> </ul> <p>Stochastic vs. Deterministic Models</p> Feature Stochastic Model Deterministic Model Randomness Yes (built into the model) No (inputs and outputs are fixed) # of outcomes Multiple, each with a probability Single, repeatable outcome Use case Systems with inherent uncertainty (e.g., finance, weather) Predictable systems Example Monte Carlo Simulation, Markov chains Simplre interest calculation"},{"location":"Stochastic%20Modeling/02-fourier/","title":"Fourier-Based Option Pricing","text":"<p>In simple models like Black-Scholes, we have closed-form solutions (thanks to Ito calculus). But for more complex models (like Heston, Jump-Diffusion, etc.), there\u2019s no closed-form formula for the price. </p> <p>So instead, we use the characteristics function (CF), and price the option using Fourier transforms</p>"},{"location":"Stochastic%20Modeling/02-fourier/#generic-workflow-for-fourier-based-option-pricing","title":"Generic workflow for Fourier-based option pricing","text":"<p>Here\u2019s a step-by-step workflow for Fourier-based option pricing in stochastic modeling:</p> <ol> <li>Model Specification: Define the model for the underlying asset prices, including the stochastic process that governs their movements.<ol> <li>Defuine the Stochastic process for the underlying asset.      1. Black-Scholes: GBM     2. Heston: Stochastic volatility      3. Merton: Jump-diffusion</li> <li>The key is that we must know the distribution of $\\log(S_T) $ or at least its characteristic function.</li> </ol> </li> <li>Characteristic Function: Derive the characteristic function of the log of the underlying asset\u2019s price. This function is crucial for the Fourier transform method.<ol> <li>Find the characteristic function \\(\\phi(u) = \\mathbb{E}[e^{iu \\log S_T}]\\) under the risk-neutral measure \\(\\mathbb{Q}\\).</li> <li>This is the bridge into frequency space. Even if the PDF is unknown, CF is often tractable.</li> </ol> </li> <li>Fourier Transform of Payoff Function: Apply the Fourier transform to the option\u2019s payoff function. This converts the payoff into a form that can be used in the Fourier domain.<ol> <li>Fourier transform the option payoff, such as \\((S_T - K)^+\\). </li> <li>This step ensures you\u2019re working in the same frequency space as the CF.</li> <li>In Carr-Madan: this involves modifying the payoff to make it square-integrable (e.g. adding a damping factor \\(e^{-\\alpha k}\\)).</li> </ol> </li> <li>Integrate Product: Integrate the product of the characteristic function and the transformed payoff function. This step involves complex mathematical integration.<ol> <li>Compute the integral: \\(\\text{Option Price} = \\int_{-\\infty}^{\\infty} \\phi(u) \\cdot \\hat{g}(u) \\, du\\) Where: \\(\\phi(u)\\) = CF of log price , \\(\\hat{g}(u)\\) = transformed payoff function </li> <li>This step is often where FFT or quadrature is used.</li> </ol> </li> <li>Inverse Fourier Transform: Perform the inverse Fourier transform to convert the result back to the time domain. This gives the option price.<ol> <li>Bring the result back to the real domain to obtain the option price: \\(f(x) = \\frac{1}{2\\pi} \\int_{-\\infty}^\\infty e^{-iux} \\hat{f}(u) \\, du\\)</li> <li>Often the inverse is embedded inside the pricing formula (e.g. Carr-Madan or Lewis), so this step is implicit.</li> </ol> </li> <li>Adjust for Model Characteristics: Make any necessary adjustments to account for specific characteristics of the model or market conditions. (like discounting)<ol> <li>Finally, multiply by \\(e^{-rT}\\) to account for the present value of the expected payoff under \\(\\mathbb{Q}\\).</li> <li>Some models require further tweaks (e.g. jump compensators, FFT damping, etc.)</li> </ol> </li> </ol> <pre><code>flowchart TD\n    A[\"1.Model Specification: Define the stochastic process (e.g. GBM, Heston, etc.)\"]\n    B[\"2.Derive Characteristic Function: Compute \u03c6(u) = E[e^{iu log S_T}] under Q\"]\n    C[\"3.Fourier Transform Payoff: Convert payoff function (e.g. (S - K)^+) to frequency space\"]\n    D[\"4.Integrate Product: Compute \u03c6(u) \u00d7 Fourier-transformed payoff\"]\n    E[\"5.Inverse Fourier Transform: Convert result back to real domain (e.g. via inverse FFT)\"]\n    F[\"6.Adjust/Discount: Apply discounting (e^{-rT}) and model-specific corrections\"]\n\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F</code></pre>"},{"location":"Stochastic%20Modeling/02-fourier/#fourier-transform","title":"Fourier Transform","text":"<p>The Fourier Transform converts a function (like a PDF) into frequency space. </p> \\[ \\hat{f}(u) = \\int_{-\\infty}^{\\infty} e^{iux} f(x) dx \\] <p>We can also recover the function using the Inverse Fourier Transform:</p> \\[ f(x) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} e^{-iux} \\hat{f}(u) du \\] <p>Paeseval\u2019s relation connects the dot product in original space and frequency space. </p> <p>The PDF(probability densitiy function) is a curve, that tells you how likely it is to see different outcomes of a random variable. The area under the curve between two points tells you the probability of the variable falling in that range. </p> <p></p> <p>Suppose you\u2019re guessing where a dart will land on a board. You can\u2019t predict exactly where it will land\u2026 But you can describe how likely it is to land in a certain area. That\u2019s what a PDF dose. </p> <p>Let\u2019s say \\(X=log(S_T)\\) (the log of future stock price)</p> <p>The PDF \\(f(x)\\) of \\(X\\) answers:</p> <p>\u201cWhat\u2019s the probability that the log of the stock price ends up around x?\u201d</p> <ul> <li>A normal distribution PDF looks like a bell curve.</li> <li>The peak is the most likely value.</li> <li>The tails show how much chance there is of extreme events.</li> </ul> <p>To price an option, we want to average all possible future outcomes, weighted by how likely they are. </p> <p>Call option price: </p> \\[ C_0 = e^{-rT} \\mathbb{E}^{\\mathbb{Q}}[(S_T - K)^+] \\] <p>We can compute this as: </p> \\[ C_0 = e^{-rT} \\int_0^\\infty (S - K)^+ \\cdot f(S)\\, dS \\] <p>Where:</p> <ul> <li>\\((S - K)^+\\) is the payoff</li> <li>\\(f(S)\\) is the PDF of the stock price under risk-neutral measure</li> </ul> <p>So: The PDF tells us how likely each payoff is, and we multiply that by the payoff and add it all up to get the option price.</p> <p>For complex models (e.g. Heston), we often don\u2019t know the PDF of S_T\u2026 but we can compute its characteristic function \u2014 and that\u2019s where Fourier methods come in!</p>"},{"location":"Stochastic%20Modeling/02-fourier/#characteristic-function-cf","title":"Characteristic Function (CF)","text":"\\[ \\hat{q}(u) = \\mathbb{E}^{\\mathbb{Q}}[e^{iuX}] \\] <ul> <li>This is the Fourier transform of the PDF of a random variable \\(X\\)</li> <li>It fully characterizes the distribution, even if the PDF is not known </li> </ul> <p>This is the key: even if we can\u2019t write down the PDF of \\(S_T\\), we can often get its CF</p> <p>Imagine you have a mysterious black box (a random variable). We can\u2019t always see its PDF, but we still want to understand its behavior - like:</p> <ul> <li>Where it\u2019s centered </li> <li>How wide it is</li> <li>How it behaves over time</li> </ul> <p>The Characteristic Function is a tool that lets you describe any random variable in a way that\u2019s super flexible - even when you don\u2019t have the PDF. </p> <p>The characteristic function of a random variable \\(X\\) is defined as: \\(\\phi_X(u) = \\mathbb{E}[e^{iuX}]\\), where:</p> <ul> <li>\\(u\\) is a real number (like a frequency),</li> <li>\\(e^{iuX}\\) is a complex exponential (don\u2019t panic \u2014 it\u2019s like encoding the shape of a wave), </li> <li>\\(\\mathbb{E}[\\,]\\) means you\u2019re taking an expected value \u2014 i.e., an average.</li> </ul> <ul> <li>The term \\(e^{iuX}\\) comes from Euler\u2019s formula: \\(e^{iuX} = \\cos(uX) + i\\sin(uX)\\) </li> </ul> <p>So what are we really doing?  -&gt; We\u2019re taking the cosine and sine of the random variable, then averaging them! This tells us: How \u201caligned\u201d the distribution is with the wave of frequency u</p> <p>A characteristic function is like a \u201cfrequency signature\u201d of a random variable. It encodes all its behavior \u2014 even if we don\u2019t have the PDF. For option pricing, the CF is often much easier to work with than the PDF, and we can use Fourier inversion to get prices directly.</p>"},{"location":"Stochastic%20Modeling/02-fourier/#lewis-2001-approach","title":"Lewis (2001) Approach","text":"<p>Uses the Fourier inersion to get the call price:</p> \\[ C_0 = S_0 - \\frac{\\sqrt{S_0 K} e^{-rT}}{\\pi} \\int_0^{\\infty} \\text{Re}\\left[ e^{izk} \\phi(z - i/2) \\right] \\frac{dz}{z^2 + 1/4} \\] <p>Where:</p> <ul> <li>\\(\\phi(u)\\): characteristic function of \\(\\log S_T\\)</li> <li>\\(k = \\log(S_0/K)\\)</li> </ul>"},{"location":"Stochastic%20Modeling/02-fourier/#carr-madan-1999-with-fft","title":"Carr-Madan (1999) with FFT","text":"<p>They modify the call price to make it square-integrable and apply FFT:</p> \\[ \\Psi(\\nu) = \\frac{e^{-rT} \\phi(\\nu - i(\\alpha+1))}{\\alpha^2 + \\alpha - \\nu^2 + i(2\\alpha + 1)\\nu} \\] <p>Then recover the price via inverse Fourier transform:</p> \\[ C_0 = \\frac{e^{-\\alpha k}}{\\pi} \\int_0^{\\infty} e^{-i \\nu k} \\Psi(\\nu) d\\nu \\] <p>This is used in practice for fast numerical pricing using FFT</p>"},{"location":"Stochastic%20Modeling/03-cf-blacksholes/","title":"Black-Scholes Characteristic Function(CF)","text":"<p>CF is defined as:</p> \\[ \\phi_X(u) = \\mathbb{E}\\left[e^{iuX}\\right] \\] <p>It\u2019s the expected value of a complex exponential, and it uniquely determines the distribution of the random variable X \u2014 like a frequency signature of the distribution. </p>"},{"location":"Stochastic%20Modeling/03-cf-blacksholes/#deriving-the-black-scholes-characteristic-function","title":"Deriving the Black-Scholes Characteristic Function","text":"<p>We assume that: </p> \\[ s_T = \\log S_T \\sim \\mathcal{N}\\left(s_0 + \\left(\\mu - \\frac{1}{2} \\sigma^2\\right)T, \\sigma^2 T \\right) \\] <p>That\u2019s just the log of the stock price under GBM, which is normally distributed. </p> <p>Then using the Definition of the CF, substitute in the normal PDF and solve:</p> \\[ \\phi_{s_T}(u) = \\int_{-\\infty}^\\infty e^{ius_T} f(s_T)\\, ds_T \\] <p>Then combine the exponentials, we get:</p> \\[ \\phi_{s_T}(u) = \\int_{-\\infty}^\\infty e^{ius_T - \\frac{(s_T - \\hat{\\mu})^2}{2 \\hat{\\sigma}^2}} \\, ds_T \\] <p>Where:</p> <ul> <li>\\(\\hat{\\mu} = s_0 + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)T\\)</li> <li>\\(\\hat{\\sigma} = \\sigma \\sqrt{T}\\)</li> </ul> <p>This is just a normal PDF wrapped in a complex exponential. </p> <p>To solve the integral, we rewrite the exponent using a completing-the-square trick:</p> \\[ ius_T - \\frac{(s_T - \\hat{\\mu})^2}{2 \\hat{\\sigma}^2} = -\\frac{(s_T - y)^2}{2\\hat{\\sigma}^2} + \\text{constants} \\] <p>We end up with:</p> \\[ \\phi_{s_T}(u) = \\exp \\left( iu \\hat{\\mu} - \\frac{1}{2} u^2 \\hat{\\sigma}^2 \\right) \\] <p>Substituiting back:</p> \\[ \\phi_{s_T}(u) = \\exp \\left( iu \\left(s_0 + \\left(\\mu - \\frac{1}{2} \\sigma^2\\right)T \\right) - \\frac{1}{2} u^2 \\sigma^2 T \\right) \\] <p>This is the closed-form CF of \\(\\log S_T\\) in the Black-Scholes model.</p> <p>This is actually the same as the CF of a normal distribution: </p> \\[ \\phi_X(u) = \\exp \\left(iu \\mu - \\frac{1}{2} u^2 \\sigma^2 \\right) \\] <p>So this confirms that:</p> <ul> <li>\\(\\log S_T\\) is normal </li> <li>The CF matches the theory</li> </ul> <p>We derived the characteristic function of \\(\\log S_T\\) under Black-Scholes by plugging the normal distribution into the definition of CF and simplifying the integral using a completing-the-square trick. This gives us a clean formula that\u2019s perfect for plugging into Fourier pricing methods.</p>"},{"location":"Stochastic%20Modeling/04-fourier-transform/","title":"Fourier-Based option pricing (BS)","text":"<p>We want to compute this integral from Carr-Madan\u2019s formula:</p> \\[ C_0 = \\frac{e^{-\\alpha k}}{\\pi} \\int_0^{\\infty} e^{-i\\nu k} \\Psi(\\nu)\\, d\\nu  \\] <p>This is the option price in the Fourier domain \u2014 but how do you compute an integral from 0 to \u221e on a computer? </p>"},{"location":"Stochastic%20Modeling/04-fourier-transform/#discrete-fourier-transform-dft","title":"Discrete Fourier Transform (DFT)","text":"<p>Trapezoidal Rule</p> <p>We truncate the upper bound (say at B) and discretize it into N steps using spacing \\(\\eta = B/N\\).  We approximate the integral as a finite sum: </p> \\[ \\int_0^B e^{-i \\nu k} \\Psi(\\nu) d\\nu \\approx \\sum_{j=1}^{N} e^{-i \\nu_j k} \\Psi(\\nu_j) \\eta \\] <p>This is the Discrete Fourier Transform (DFT):</p> \\[ C_T(k) \\approx \\frac{e^{-\\alpha k}}{\\pi} \\sum_{j=1}^{N} e^{-i \\nu_j k} \\Psi(\\nu_j) \\eta \\] <p>Where: \\(\\nu_j = \\eta(j - 1)\\)</p>"},{"location":"Stochastic%20Modeling/04-fourier-transform/#fast-fourier-transform-fft","title":"Fast Fourier Transform (FFT)","text":"<p>Now here\u2019s the cool part: We can compute all these integrals for a range of strikes using a single FFT \u2014 super efficiently. </p> <p>This is possible because DFT is mathematically the same structure as FFT. </p> <p>We define:</p> <ul> <li>A grid of frequencies \\(\\nu_j = \\eta(j - 1)\\)</li> <li>A grid of strikes \\(k_u = -b + \\lambda(u - 1)\\) </li> </ul> <p>Then we can write the FFT-friendly version: </p> \\[ C_T(k_u) \\approx \\frac{e^{-\\alpha k_u}}{\\pi} \\sum_{j=1}^{N} e^{-i \\eta \\lambda (j-1)(u-1)} \\cdot x_j \\] <p>Where:</p> <ul> <li>\\(x_j = e^{ib\\nu_j} \\Psi(\\nu_j) \\eta\\)</li> <li>\\(\\eta \\lambda = \\frac{2\\pi}{N}\\) ensures orthogonality for FFT</li> </ul> <p>Now this sum is exactly what FFT is designed to compute!</p>"},{"location":"Stochastic%20Modeling/04-fourier-transform/#simpsons-rule-for-better-accuracy","title":"Simpson\u2019s Rule (for better accuracy)","text":"<p>You can replace the trapezoidal weights with Simpson\u2019s Rule for improved accuracy: </p> \\[ \\int f(x) dx \\approx \\frac{\\eta}{3} \\left[f_0 + 4f_1 + 2f_2 + 4f_3 + \\dots + f_N\\right] \\] <p>This becomes:</p> \\[ C_T(k_u) \\approx \\frac{e^{-\\alpha k_u}}{\\pi} \\sum_{j=1}^N e^{-i \\eta \\lambda (j-1)(u-1)} x_j \\cdot \\left(\\frac{\\eta}{3}(3 + (-1)^j - \\delta_{j-1})\\right) \\] <p>Instead of computing the Carr-Madan integral directly, we discretize it using the trapezoidal or Simpson\u2019s rule, then convert it into a DFT \u2014 and accelerate the computation using the FFT algorithm. This gives us option prices across a whole range of strikes in one fast operation</p> <ul> <li>This version works best for ITM/ATM options (i.e. near-the-money)</li> <li>For OTM cases, tweaks are needed to stabilize integrability \u2014 this will come in future lessons.</li> </ul>"},{"location":"Stochastic%20Modeling/04-fourier-transform/#fourier-based-option-pricing","title":"Fourier-based Option Pricing","text":""},{"location":"Stochastic%20Modeling/04-fourier-transform/#carr-madan-fft-pricing","title":"Carr-Madan FFT Pricing","text":"<p>The Carr-Madan method gives us a way to price European call options using the FFT by converting the payoff into the Fourier domain.</p> <p>We compute:</p> \\[ \\psi(u) = \\frac{e^{-rT} \\phi(u - (\u03b1 + 1)i)}{\u03b1^2 + \u03b1 - u^2 + i(2\u03b1 + 1)u} \\] <p>Where:</p> <ul> <li>\\(\\phi(u)\\) is the characteristic function of \\(\\log(S_T)\\),</li> <li>\u03b1 is a damping factor to make the call price integrable,</li> <li>\\(\\psi(u)\\) is then inverse Fourier transformed using FFT to get prices.</li> </ul> <p>Then we recover the original prices:</p> \\[ C(K) = \\frac{e^{-\u03b1k}}{\\pi} \\text{Re}(\\text{FFT}) \\] <p>$$ C(K) = \\frac{e^{-\u03b1k}}{\u03c0} \\text{Re}(FFT of \u03c8) $$ Note that By default, numpy.fft.fft() returns an unscaled sum, while the true integral approximates: </p> \\[ \\int f(u)\\, du \\approx \\eta \\sum f(u_j) \\]"},{"location":"Stochastic%20Modeling/04-fourier-transform/#lewis-vs-carr-madan","title":"Lewis vs. Carr-Madan","text":"<p>The Lewis (2001) and Carr-Madan (1999) methods are both Fourier-based approaches for option pricing, and while they aim for similar goals \u2014 computing option prices using the characteristic function \u2014 they differ in how they handle the Fourier transform and what functions they transform. </p> <p>Both methods:</p> <ul> <li>Use the characteristic function \\(\\phi(u) = \\mathbb{E}[e^{iu \\log S_T}]\\)</li> <li>Price European options (typically calls) by moving into the frequency domain</li> <li>Use Fourier transforms to handle integrations more efficiently and stably</li> <li>Work especially well for non-Black-Scholes models, like Heston or Variance Gamma</li> </ul>"},{"location":"Stochastic%20Modeling/04-fourier-transform/#core-difference-what-gets-transformed","title":"Core Difference: What Gets Transformed?","text":"Carr-Madan (1999) Lewis (2001) Transforms Damped call price e^{\\alpha k} C(k) Payoff function (e^{k} - K)^+ Key Parameter Introduces damping factor \\alpha &gt; 0 No damping required if CF is integrable Approach Fourier transform of the price Fourier inversion formula directly Use of FFT? Yes, FFT is used in pricing Also compatible with FFT (though less common) Works with A wide class of L\u00e9vy models Same, but cleaner when CF is integrable Main paper Carr &amp; Madan: Option valuation using FFT Lewis: A Simple Option Formula for General Jump-Diffusions"},{"location":"Stochastic%20Modeling/04-fourier-transform/#carr-madan","title":"Carr-Madan","text":"<ul> <li>Defines a modified call price: \\(\\tilde{C}(k) = e^{\\alpha k} C(k)\\) </li> </ul> <ul> <li>Then takes its Fourier transform: $ \\mathcal{F}[\\tilde{C}(k)] = \\int_{-\\infty}^{\\infty} e^{iuk} \\tilde{C}(k) dk $</li> <li>Inversion (via FFT) is used to get back \\(C(k)\\)</li> </ul> <p>Why damping? Because the raw call price function C(k) isn\u2019t square-integrable (blows up at infinity), so Carr-Madan multiplies by an exponential decay factor to make the Fourier transform valid. </p>"},{"location":"Stochastic%20Modeling/04-fourier-transform/#lewis","title":"Lewis","text":"<ul> <li>Works with a representation of the option price using the inverse Fourier transform: \\(C(K) = e^{-rT} \\cdot \\frac{1}{2\\pi} \\int_{\\mathbb{R}} \\frac{\\phi(u - i)}{iu} e^{-iuk} du\\) </li> <li>No damping required, but assumes the characteristic function is integrable</li> <li>Mathematically neater, often more elegant (but sometimes numerically more delicate)</li> </ul> \\[ C(K) = \\frac{S_0 - \\sqrt{S_0 K} e^{-rT}}{\\pi} \\int_0^\\infty \\text{Re} \\left( \\frac{e^{i u \\ln(S_0/K)} \\phi(u - 0.5i)}{u^2 + 0.25} \\right) \\, du \\]"},{"location":"Stochastic%20Modeling/04-fourier-transform/#coding","title":"Coding","text":"Python<pre><code># Black-Scholes Analytical \n\nfrom wqu.dp import BlackScholes\n\n# Example: A call option\n\n# S0 = 100\n# K = 100\n# T = 1\n# r = 0.05\n# sigma = 0.2\n\nbs = BlackScholes(S0=100, K=100, T=1, r=0.05, sigma=0.2, option_type=\"call\")\n\nprint(\"Option Price:\", bs.price())\nprint(\"Delta:\", bs.delta())\nprint(\"Gamma:\", bs.gamma())\nprint(\"Vega:\", bs.vega())\nprint(\"Theta:\", bs.theta())\nprint(\"Rho:\", bs.rho())\n</code></pre> Text Only<pre><code>Option Price: 10.450583572185565\nDelta: 0.6368306511756191\nGamma: 0.018762017345846895\nVega: 37.52403469169379\nTheta: -6.414027546438197\nRho: 53.232481545376345\n</code></pre> Python<pre><code>from wqu.sm import BlackScholesFourier\n\nS0 = 100\nK = 100\nT = 1\nr = 0.05\nsigma = 0.2\n\nbs_fft = BlackScholesFourier(S0, K, T, r, sigma, method=\"carr-madan\", option_type=\"call\")\nprint(\"Carr-Madan FFT Call Price:\", bs_fft.price())\n\nbs_lewis = BlackScholesFourier(S0, K, T, r, sigma, method=\"lewis\", option_type=\"call\")\nprint(\"Lewis Method Call Price:\", bs_lewis.price())\n</code></pre> Text Only<pre><code>Carr-Madan FFT Call Price: 10.450583529672013\nLewis Method Call Price: 10.450583572184783\n</code></pre>"},{"location":"Stochastic%20Modeling/05-heston/","title":"Fourier Methods for Heston Model","text":"<p>We are extending our Fourier-based pricing methods \u2014 like we did in Black-Scholes \u2014 to a more realistic model of financial markets called the Heston Model, which allows volatility to be stochastic (i.e., random). </p>"},{"location":"Stochastic%20Modeling/05-heston/#the-pricing-equation-lewis-2001","title":"The Pricing Equation (Lewis 2001)","text":"<p>Under the Heston model, the European call option price is given by this integral (Lewis-style): </p> \\[ C_0 = S_0 - \\frac{\\sqrt{S_0 K} \\, e^{-rT}}{\\pi} \\int_0^{\\infty} \\text{Re} \\left[ \\frac{e^{i u \\log(S_0/K)} \\, \\phi(u - i/2)}{u^2 + 1/4} \\right] du \\] <p>This formula has three key parts:</p> <ul> <li>\\(\\phi(u)\\): Characteristic function of the log-price under the Heston model.</li> <li>\\(\\text{Re}[\\cdot]\\): Take only the real part.</li> <li>\\(\\int_0^\\infty \\cdots du\\): Numerically integrated.</li> </ul> <p>The Heston model assumes:</p> <ul> <li>The asset price \\(S_t\\) and its volatility \\(\\nu_t\\) both follow stochastic (random) processes.</li> <li>The volatility itself is mean-reverting \u2014 it wants to go back to some long-term average.</li> </ul> <p>It adds realism, especially for modeling:</p> <ul> <li>Volatility smiles/skews</li> <li>Market shocks</li> <li>Fat tails in return distribution</li> </ul>"},{"location":"Stochastic%20Modeling/05-heston/#characteristic-function-in-heston-hu-t","title":"Characteristic Function in Heston (\u03c6H(u, T))","text":"<p>This is the most technical part: deriving the characteristic function under Heston dynamics. It\u2019s a complex exponential with parts: </p> \\[ \\phi_H(u, T) = \\exp \\left( H_1(u, T) + H_2(u, T) \\cdot \\nu_0 \\right) \\] <p>Where:</p> <ul> <li>\\(H_1(u, T)\\) and \\(H_2(u, T)\\) are expressions derived from solving the SDEs.</li> </ul> <ul> <li> <p>They depend on:</p> <ul> <li>\\(\\kappa_\\nu\\): speed of mean reversion</li> <li>\\(\\theta_\\nu\\): long-term mean of variance</li> <li>\\(\\sigma_\\nu\\): volatility of variance (vol of vol)</li> <li>\\(\\rho\\): correlation between asset returns and variance</li> <li>\\(\\nu_0\\): initial variance level</li> </ul> </li> </ul> <p>\u201cHow does the distribution of log-prices change when both the price and its volatility are random?\u201d</p>"},{"location":"Stochastic%20Modeling/05-heston/#how-to-price-an-option-with-it","title":"How to Price an Option with It?","text":"<p>Same idea as Black-Scholes Lewis-style pricing:</p> <ol> <li>Plug \\(\u03c6H(u \u2212 i/2)\\) into the integral formula.</li> <li>Use a quadrature method (like Simpson\u2019s Rule or scipy.integrate.quad) to numerically integrate it.</li> <li>Done \u2014 you get a call price.</li> </ol>"},{"location":"Stochastic%20Modeling/05-heston/#calibration-of-heston-model","title":"Calibration of Heston Model","text":"<p>Since the model has 5 unknown parameters:  \\(\\kappa_\\nu, \\theta_\\nu, \\sigma_\\nu, \\rho, \\nu_0\\)</p> <p>We calibrate it like this:</p> <ol> <li> <p>Define a loss function = squared difference between market prices and model prices.</p> </li> <li> <p>Use optimization (scipy.optimize) to minimize that loss.</p> </li> <li> <p>Often we do it in 2 stages:</p> <ul> <li>Coarse grid search (brute force)</li> <li>Fine optimization (e.g., L-BFGS-B)</li> </ul> </li> </ol>"},{"location":"Stochastic%20Modeling/05-heston/#coding","title":"Coding","text":"Python<pre><code>import pandas as pd\nfrom datetime import datetime\nfrom wqu.sm import HestonCalibrator\n\n# Load from CSV\ndata_path = \"option_data.csv\"\ndata = pd.read_csv(data_path)\n\n# Set index level and tolerance\nS0 = 3225.93\ntol = 0.02\n\n# Filter near-the-money European call options\noptions = data[(abs(data[\"Strike\"] - S0) / S0) &lt; tol].copy()\noptions[\"Date\"] = pd.to_datetime(options[\"Date\"])\noptions[\"Maturity\"] = pd.to_datetime(options[\"Maturity\"])\noptions[\"T\"] = (options[\"Maturity\"] - options[\"Date\"]).dt.days / 365\noptions[\"r\"] = 0.02  # constant short rate\n\n# Initialize and run calibration\ncalibrator = HestonCalibrator(S0=S0, options_df=options)\noptimal_params = calibrator.calibrate()\n\n# Display results\nprint(\"Optimal Parameters:\", optimal_params)\n</code></pre> Text Only<pre><code>&gt;&gt;&gt; Starting brute-force search...\n   0 | [ 2.5   0.01  0.05 -0.75  0.01] | MSE: 820.892168 | Min MSE: 820.892168\n  25 | [ 2.5   0.02  0.05 -0.75  0.02] | MSE: 23.863624 | Min MSE: 21.567743\n  50 | [ 2.5   0.02  0.25 -0.75  0.03] | MSE: 89.654952 | Min MSE: 21.567743\n  75 | [ 2.5   0.03  0.15 -0.5   0.01] | MSE: 193.282610 | Min MSE: 21.567743\n 100 | [ 2.5   0.04  0.05 -0.5   0.02] | MSE: 176.339739 | Min MSE: 21.567743\n 125 | [ 2.5   0.04  0.25 -0.5   0.03] | MSE: 486.964581 | Min MSE: 21.567743\n 150 | [ 7.5   0.01  0.15 -0.25  0.01] | MSE: 840.337090 | Min MSE: 21.567743\n 175 | [ 7.5   0.02  0.05 -0.25  0.02] | MSE: 24.810371 | Min MSE: 21.567743\n 200 | [ 7.5   0.02  0.25 -0.25  0.03] | MSE: 24.834228 | Min MSE: 21.567743\n 225 | [7.5  0.03 0.15 0.   0.01] | MSE: 110.936421 | Min MSE: 21.567743\n 250 | [7.5  0.04 0.05 0.   0.02] | MSE: 540.182792 | Min MSE: 21.567743\n 275 | [7.5  0.04 0.25 0.   0.03] | MSE: 783.221740 | Min MSE: 21.567743\n&gt;&gt;&gt; Refining with local search...\n 300 | [ 2.61379559  0.00992657  0.15610448 -0.76361614  0.02778356] | MSE: 8.045766 | Min MSE: 7.795453\n 325 | [ 1.9152359   0.01257942  0.16036675 -0.91693167  0.0248233 ] | MSE: 6.300806 | Min MSE: 6.146318\n 350 | [ 2.04831069  0.01215428  0.15832201 -0.89057611  0.02532865] | MSE: 6.150503 | Min MSE: 6.144623\n 375 | [ 2.0376908   0.01207312  0.16816435 -0.86785979  0.02553311] | MSE: 6.097042 | Min MSE: 6.075189\n 400 | [ 1.97316132  0.01247835  0.2032535  -0.83478704  0.0254568 ] | MSE: 6.001525 | Min MSE: 5.996115\n 425 | [ 2.07617861  0.01268556  0.21375606 -0.83213139  0.02575716] | MSE: 5.947748 | Min MSE: 5.947748\n 450 | [ 2.66904762  0.0147503   0.22891593 -0.87575667  0.02607257] | MSE: 5.683904 | Min MSE: 5.683904\n 475 | [ 3.14901508  0.01554998  0.22701309 -0.86349685  0.02615741] | MSE: 5.357630 | Min MSE: 5.357630\n 500 | [ 3.75301757  0.0179153   0.33579328 -0.72953664  0.02611118] | MSE: 4.602526 | Min MSE: 4.498631\n 525 | [ 5.15416061  0.01857864  0.40457683 -0.45664742  0.0270172 ] | MSE: 3.894461 | Min MSE: 3.824773\n 550 | [ 5.14078039  0.01861684  0.42859861 -0.43432012  0.02728158] | MSE: 3.769001 | Min MSE: 3.749195\n 575 | [ 5.0507416   0.01868091  0.43385652 -0.44775932  0.02732562] | MSE: 3.718624 | Min MSE: 3.716546\n 600 | [ 5.05235394  0.01871275  0.43473462 -0.44693948  0.02730235] | MSE: 3.716004 | Min MSE: 3.715792\n 625 | [ 5.05371685  0.01872767  0.43504931 -0.44691718  0.0272971 ] | MSE: 3.715524 | Min MSE: 3.715392\n 650 | [ 5.04446488  0.01872907  0.43469053 -0.44848558  0.02728228] | MSE: 3.715380 | Min MSE: 3.715376\n 675 | [ 5.04382644  0.0187266   0.43463479 -0.44869357  0.02728557] | MSE: 3.715374 | Min MSE: 3.715374\n 700 | [ 5.04426287  0.01872709  0.4346593  -0.44857764  0.02728496] | MSE: 3.715373 | Min MSE: 3.715373\n 725 | [ 5.04476043  0.01872427  0.43464808 -0.44841756  0.02728689] | MSE: 3.715371 | Min MSE: 3.715371\n 750 | [ 5.04505376  0.01872602  0.43468094 -0.44837446  0.02728584] | MSE: 3.715370 | Min MSE: 3.715370\n 775 | [ 5.04707738  0.01872566  0.434764   -0.44801571  0.02728898] | MSE: 3.715367 | Min MSE: 3.715367\n 800 | [ 5.04731712  0.01872561  0.43477373 -0.44796137  0.02728913] | MSE: 3.715367 | Min MSE: 3.715367\n 825 | [ 5.04735223  0.01872569  0.43477611 -0.44795766  0.02728916] | MSE: 3.715367 | Min MSE: 3.715367\n 850 | [ 5.04735429  0.0187257   0.43477637 -0.44795746  0.02728915] | MSE: 3.715367 | Min MSE: 3.715367\n 875 | [ 5.04735384  0.01872571  0.43477645 -0.44795738  0.02728914] | MSE: 3.715367 | Min MSE: 3.715367\n 900 | [ 5.04736306  0.01872573  0.43477709 -0.44795509  0.02728912] | MSE: 3.715367 | Min MSE: 3.715367\n 925 | [ 5.04735787  0.01872573  0.43477684 -0.44795621  0.02728912] | MSE: 3.715367 | Min MSE: 3.715367\nOptimization terminated successfully.\n         Current function value: 3.715367\n         Iterations: 479\n         Function evaluations: 798\nOptimal Parameters: [ 5.04735844  0.01872573  0.43477689 -0.44795617  0.02728912]\n</code></pre>"},{"location":"Stochastic%20Modeling/06-merton/","title":"Merton Model","text":"<p>The Merton Model adds a simple twist to the classic Black-Scholes setup: \u2192 It allows for jumps in the price of an asset. Imagine a stock doesn\u2019t always move smoothly \u2014 sometimes it jumps up or down due to surprise news or shocks. Merton modeled this using a Poisson jump process on top of the regular Brownian motion.</p> <p>The asset price follows:</p> \\[ dS_t = (r - r_J) S_t \\, dt + \\sigma S_t \\, dZ_t + J_t S_t \\, dN_t \\] <p>Where:</p> <ul> <li>\\(r\\) is the risk-free rate.</li> </ul> <ul> <li>\\(\\sigma\\) is volatility.</li> </ul> <ul> <li>\\(Z_t\\) is a Brownian motion.</li> </ul> <ul> <li>\\(N_t \\sim \\text{Poisson}(\\lambda)\\) \u2014 random jump times.</li> </ul> <ul> <li> <p>\\(J_t\\) is the jump size:</p> <p>\\(\\log(1 + J_t) \\sim \\mathcal{N}(\\log(1 + \\mu_J) - \\frac{\\delta^2}{2}, \\delta^2)\\)</p> </li> </ul> <ul> <li>\\(r_J = \\lambda \\left(e^{\\mu_J + \\delta^2/2} - 1\\right)\\) is a correction to make the model risk-neutral.</li> </ul>"},{"location":"Stochastic%20Modeling/06-merton/#characteristic-function","title":"Characteristic Function","text":"<p>We can price European options via Lewis (2001) using the characteristic function: </p> \\[ \\phi(u, T) = \\exp\\left( \\left(i u \\omega - \\frac{1}{2} u^2 \\sigma^2 + \\lambda (e^{i u \\mu_J - \\frac{1}{2} u^2 \\delta^2} - 1) \\right) T \\right) \\] <p>Where: \\(\\omega = r - \\frac{1}{2} \\sigma^2 - \\lambda (e^{\\mu_J + \\delta^2/2} - 1)\\)</p>"},{"location":"Stochastic%20Modeling/06-merton/#lewis-pricing-formula","title":"Lewis Pricing Formula","text":"<p>Given \\(\\phi(u, T)\\), the price of a call option is: </p> <p>$$ C_0 = S_0 - \\sqrt{S_0 K} e^{-rT} \\cdot \\frac{1}{\\pi} \\int_0^\\infty \\text{Re} \\left[ e^{i u \\log(S_0/K)} \\cdot \\phi(u - i/2, T) \\right] \\cdot \\frac{1}{u^2 + \\frac{1}{4}} du $$ This is the semi-analytical expression.</p>"},{"location":"Stochastic%20Modeling/06-merton/#code","title":"Code","text":"Python<pre><code>from wqu.sm import MertonFourier\n\nS0 = 100\nK = 100\nT = 1\nr = 0.05\nsigma = 0.4\nlam = 1\nmu = -0.2\ndelta = 0.1\n\nmerton = MertonFourier(S0, K, T, r, sigma, lam, mu, delta)\nprint(f\"Merton Call Option Price (Lewis method): {merton.price():.6f}\")\n</code></pre> Text Only<pre><code>Merton Call Option Price (Lewis method): 19.947854\n</code></pre> Python<pre><code>merton = MertonFourier(\n    S0=100, K=100, T=1, r=0.05,\n    sigma=0.4, lam=1, mu=-0.2, delta=0.1,\n    option_type=\"call\"\n)\n\nmerton.plot(K_range=(60, 140))\n</code></pre> Python<pre><code>import pandas as pd\nfrom wqu.sm import MertonCalibrator\n\n# Load the dataset\ndf = pd.read_csv(\"option_data_M2.csv\")\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf[\"Maturity\"] = pd.to_datetime(df[\"Maturity\"])\ndf[\"T\"] = (df[\"Maturity\"] - df[\"Date\"]).dt.days / 365\ndf[\"r\"] = 0.005\n\n# Set tolerance and filter ATM options\nS0 = 3225.93\ntol = 0.02\noptions = df[(abs(df[\"Strike\"] - S0) / S0) &lt; tol].copy()\n\n# Run calibration\ncalibrator = MertonCalibrator(S0, options)\nopt_params = calibrator.calibrate()\nprint(\"Optimal Parameters:\", opt_params)\n</code></pre> Text Only<pre><code>   0 | [ 0.075  0.1   -0.5    0.1  ] |  31.540 |  31.540\n  50 | [ 0.075  0.3   -0.1    0.3  ] |  22.852 |  11.298\n 100 | [ 0.1  0.2 -0.2  0.2] |  19.922 |   8.654\n 150 | [ 0.125  0.1   -0.3    0.1  ] |  10.704 |   5.571\n 200 | [ 0.125  0.4   -0.5    0.3  ] |  55.500 |   4.662\n 250 | [0.15 0.2  0.   0.2 ] |   6.619 |   3.586\n 300 | [ 0.175  0.1   -0.1    0.1  ] |  14.171 |   3.586\n 350 | [ 0.175  0.4   -0.3    0.3  ] |  54.376 |   3.586\n 400 | [ 0.2  0.3 -0.4  0.2] |  63.380 |   3.586\n 450 | [ 0.14702168  0.19533978 -0.10189428  0.10218084] |   3.495 |   3.428\n 500 | [ 0.14987758  0.11503181 -0.14398098  0.09850597] |   3.401 |   3.401\n 550 | [ 0.15597729  0.01124105 -0.20255149  0.07785796] |   3.359 |   3.359\n 600 | [ 0.15617567  0.00947711 -0.20364524  0.07721602] |   3.358 |   3.358\nOptimization terminated successfully.\n         Current function value: 3.358419\n         Iterations: 107\n         Function evaluations: 183\nOptimal Parameters: [ 0.15619381  0.009201   -0.20380034  0.07715499]\n</code></pre> Python<pre><code># Plot fit\ncalibrator.plot(opt_params)\n</code></pre>"},{"location":"Stochastic%20Modeling/07-bates/","title":"Bates Model","text":"<p>So far we have two powerful models: </p> <ul> <li>Heston (random/stochastic volatility)</li> <li>Merton (jumps in asset prices)</li> </ul> <p>The bates model blends both, giving you a \u201csupermodel\u201d of asset prices that can handle: </p> <ul> <li>Slowly evolving volatility </li> <li>Sudden big jumps.</li> </ul> <p>We will use the Lewis integral formula and the Carr-Madan (FFT) approach. This means:</p> <ul> <li>We take the Bates characteristic function (which is Heston\u2019s CF x adjusted Merton jumps),</li> <li>Then either directly integrate (Lewis),</li> <li>Or use discrete transforms (Carr-Madan/FFT)</li> </ul> <p>So Bates = Heston + Merton</p> <p>Bates Pricing Approaches</p> <pre><code>flowchart LR\n    A((Bates Model)) --&gt; B[Lewis Integral Pricing]\n    A((Bates Model)) --&gt; C[Carr-Madan / FFT Pricing]\n\n    B --&gt; D((Option Price))\n    C --&gt; D((Option Price))\n</code></pre>"},{"location":"Stochastic%20Modeling/07-bates/#bates-model_1","title":"Bates Model","text":"<p>The Bates model describes the evolution of the stock price S_t and variance v_t with the following dynamics: </p> \\[ \\begin{aligned} dS_t &amp;= \\mu S_t dt + \\sqrt{v_t} S_t dW_t^S + (J - 1) S_t dN_t \\\\ dv_t &amp;= \\kappa (\\theta - v_t) dt + \\sigma \\sqrt{v_t} dW_t^v \\\\ \\end{aligned} \\] <ul> <li>\\(W_t^S, W_t^v\\) are two Brownian motions with correlation \\(\\rho\\),</li> <li>\\(N_t\\) is a Poisson process (jumps),</li> <li>\\(J \\sim \\log \\mathcal{N}(\\mu_J, \\delta_J^2)\\) represents the jump size.</li> </ul> <ul> <li>Volatility itself fluctuates over time: this explains why option prices don\u2019t fit the Black-Scholes model well.</li> <li>Jumps add realism: big news or events can make stock prices jump.</li> </ul> <p>So Bates gives a more flexible, accurate picture of real market dynamics than Heston or Merton alone. </p>"},{"location":"Stochastic%20Modeling/07-bates/#characteristic-function-cf","title":"Characteristic Function (CF)","text":"<p>The CF in Bates is: </p> \\[ \\phi(u) = \\phi_{Heston}(u) \\cdot \\phi_{Jump}(u) \\] <p>Where:</p> <ul> <li>\\(\\phi_{Heston}(u)\\): characteristic function of log-price under Heston.</li> <li>\\(\\phi_{Jump}(u) = \\exp\\left( \\lambda T \\left( e^{i u \\mu_J - \\frac{1}{2} u^2 \\delta_J^2} - 1 \\right) \\right)\\)</li> </ul> <p>This multiplication is possible because the Heston and jump components are independent.</p> <p>We can then plug this into the Lewis (2001) or Carr-Madan (1999) pricing formulas to compute European option prices via Fourier techniques. </p> <pre><code>graph TD\n    A[Start: Bates Model] --&gt; B[Heston Process for Volatility]\n    A --&gt; C[Merton Jumps for Prices]\n    B --&gt; D[\"Characteristic Function \u03c6_Heston(u)\"]\n    C --&gt; E[\"Characteristic Function \u03c6_Jump(u)\"]\n    D --&gt; F[\"\u03c6(u) = \u03c6_Heston(u) \u00d7 \u03c6_Jump(u)\"]\n    E --&gt; F\n    F --&gt; G[Option Pricing via Fourier Transform]</code></pre> <p>The Bates model is a combination of Heston (for volatility) and Merton (for jumps). The asset price changes continuously with stochastic volatility, but it can also jump at random times. We find the total characteristic function by multiplying the individual CFs for Heston and Merton. This is then used in Lewis or Carr-Madan pricing frameworks.</p>"},{"location":"Stochastic%20Modeling/07-bates/#bates-calibration","title":"Bates Calibration","text":"<p>Imagine you\u2019re trying to predict the price of an option, but the market is messy. Prices can move smoothly (like in Black-Scholes) and suddenly jump due to unexpected news. Plus, the volatility (how shaky prices are) also changes over time.</p> <p>The Bates model combines:</p> <ul> <li>The Heston model (volatility that changes randomly),</li> <li>And the Merton jump-diffusion model (sudden jumps in price).</li> </ul> <p>So, we\u2019re dealing with:</p> <ul> <li>Random drift </li> <li>Random volatility </li> <li>Random jumps </li> </ul> <p>Our goal is to find the set of parameters for this model that best fits the market data \u2014 this is called calibration.</p>"},{"location":"Stochastic%20Modeling/07-bates/#params-to-calibrate-estimate","title":"Params to calibrate (estimate)","text":"<p>We want to estimate these parameters:</p> <ul> <li>\\(\\kappa\\): speed of mean reversion of volatility</li> <li>\\(\\theta\\): long-term variance</li> <li>\\(\\sigma_v\\): volatility of volatility (vol of vol)</li> <li>\\(\\rho\\): correlation between price and variance</li> <li>\\(v_0\\): initial variance</li> <li>\\(\\lambda\\): jump intensity (how often jumps occur)</li> <li>\\(\\mu\\): average jump size</li> <li>\\(\\delta\\): std dev of jump size</li> </ul> <p>We do this by minimizing the error between market prices and model prices using an optimization technique.</p>"},{"location":"Stochastic%20Modeling/07-bates/#code","title":"Code","text":"Python<pre><code>bates = BatesFourier(\n    S0=100, K=100, T=1, r=0.05,\n    sigma=0.15,          # sigma_v\n    kappa=1.5,\n    theta=0.02,\n    v0=0.01,\n    rho=0.1,\n    lam=0.25,            # lambda\n    mu=-0.2,\n    delta=0.1,\n    method=\"lewis\",\n    option_type=\"call\"\n)\n\nprint(f\"Bates Call Price (Lewis method): {bates.price():.9f}\")\n</code></pre> Text Only<pre><code>Bates Call Price (Lewis method): 8.904718864\n</code></pre> Python<pre><code>bates2 = BatesFourier(\n    S0=100, K=100, T=1, r=0.05,\n    sigma=0.15,          # sigma_v\n    kappa=1.5,\n    theta=0.02,\n    v0=0.01,\n    rho=0.1,\n    lam=0.25,            # lambda\n    mu=-0.2,\n    delta=0.1,\n    method=\"carr-madan\",\n    option_type=\"call\"\n)\n\nprint(f\"Bates Call Price (Carr-Madan method): {bates2.price():.9f}\")\n</code></pre> Text Only<pre><code>Bates Call Price (Carr-Madan method): 8.904718821\n</code></pre>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/01-index/","title":"Reinforcement Learning","text":""},{"location":"Stochastic%20Modeling/08-reinforcement-learning/01-index/#reinforcement-learning-into","title":"Reinforcement Learning Into","text":""},{"location":"Stochastic%20Modeling/08-reinforcement-learning/01-index/#what-is-reinforcement-learning","title":"What is Reinforcement Learning?","text":"<p>Imagine teaching a dog tricks. </p> <ul> <li>You say \u201csit\u201d \ud83d\udc36,</li> <li>If the dog sits, you give it a treat \ud83c\udf56, </li> <li>If not, no treat. </li> </ul> <p>Over time, the dog learns that sitting when you say \u201csit\u201d gets a reward, and it dose it more often. </p> <p>Reinforcement Learning (RL) is just like that - but for computers and algorithms. </p> <p>It\u2019s a way for machines to learn how to make decisions by trying things out and getting rewards or penalties. </p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/01-index/#key-concepts-in-rl","title":"Key Concepts in RL","text":"<p>let\u2019s break down RL into its key components using intuitive examples:</p> RL Concept Dog Analogy Financial Analogy (Trading Bot) Agent The dog The trading algorithm Environment Your living room The financial market Action Sit, bark, roll Buy, sell, hold State Is the dog standing or sitting? Stock prices, indicators, portfolio state Reward Getting a treat Profit from a trade or return on investment Policy Rule for behavior Strategy for choosing actions (buy/sell) based on market state"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/01-index/#how-dose-learning-happen","title":"How dose learning happen ?","text":"<p>Trial-and-error:</p> <ul> <li>The agent starts by exploring randomly (e.g., random trades). </li> <li>It gets  feedback from the environment: profit or loss</li> <li>It learns over time to favor actions that lead to better outcomes</li> </ul>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/01-index/#formal-math-view","title":"Formal Math View","text":"<p>In RL, we model problems using a Markov Decision Process (MDP). </p> <p>An MDP is a tuple:</p> \\[ MDP = (S,A,P,R,\\gamma) \\] <p>Where: </p> <ul> <li>\\(S\\): Set of states (e.g., stock prices, portfolio) </li> <li>\\(A\\): Set of actions (e.g., buy/sell/hold)</li> <li>\\(P(s'|s,a)\\): Transition probability from state \\(s\\) to \\(s'\\) when taking action \\(a\\)</li> <li>\\(R(s,a)\\): Reward function </li> <li>\\(\\gamma \\in [0,1]\\): Discount factor (how much future rewards are worth today)</li> </ul> <p>The goal: learn a policy \\(\\pi(a|s)\\) that maximizes the expected reward over time. </p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/01-index/#the-core-equation-bellman-equation","title":"The Core Equation (Bellman Equation)","text":"<p>The Bellman Equation tells how to think about value in TL. </p> \\[ V^{\\pi}(s) = \\mathbb{E}_{\\pi} \\left[ R(s,a) + \\gamma V^{\\pi}(s{\\prime}) \\right] \\] <p>Tis says:</p> <p>The value of a state is the reward you get now plus the value of the next state, discounted. </p> <p>In finance: </p> <ul> <li>\\(V^\\pi(S)\\): Expected return from current portfolio state </li> <li>\\(R(s,a)\\): Profit/loss from an action </li> <li>\\(\\gamma\\): Time-value of money </li> </ul>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/","title":"Markov Chains","text":""},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#tldr","title":"TL;DR","text":"<p>A Markov Chain is a model where you move between states, and your next move depends only on where you are now. We use a transition matrix to represent the rules, and sometimes the system settles into a long-term distribution called the stationary distribution. In finance, this is super useful for modeling credit rating transitions, especially with absorbing states like default.</p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#intro","title":"Intro","text":"<p>Imagine a simple board game where you throw a dice \ud83c\udfb2, and depending on the result, you move to a different square. Each square has arrow showing where you might land next - based only on where you are now, not how you got there. </p> <p>This is the idea of a Markov Chain. </p> <p>A Markov Chain is a system that moves between states, and the next move depdns only on the current state, not the full history.</p> <p></p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#core-concepts-with-analogies-credit-rating","title":"Core Concepts with Analogies (Credit Rating)","text":"Concept Meaning Analogy State A situation or status (e.g., credit rating AA) Square on the board Transition Moving from one state to another Rolling a die and moving forward Transition matrix Table showing the probabilities of moving from one state to another Rules for dice outcomes Stationary distribution Long-term behavior: how often you land on each state Where you\u2019ll spend most of your time Absorbing state A state that, once entered, you never leave (like default) A square that ends the game"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#transition-matrix","title":"Transition Matrix","text":"<p>Let\u2019s say you have \\(N\\) states. The matrix \\(P\\) of transition probabilities looks like this:</p> \\[ P = \\begin{bmatrix} p_{11} &amp; p_{12} &amp; \\cdots &amp; p_{1N} \\\\ p_{21} &amp; p_{22} &amp; \\cdots &amp; p_{2N} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ p_{N1} &amp; p_{N2} &amp; \\cdots &amp; p_{NN} \\\\ \\end{bmatrix} \\] <p>And each row must sum to 1:</p> \\[ \\sum_{j=1}^{N} p_{ij} = 1 \\quad \\text{for all } i \\]"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#stationary-distribution","title":"Stationary Distribution","text":"<p>As time goes on, the Markov chain might settle into a pattern where it \u201cspends\u201d time in states according to a fixed distribution \\(\\pi\\):</p> \\[ \\pi = \\pi P \\quad \\text{where} \\quad \\sum_{k=1}^{N} \\pi_k = 1, \\quad \\pi_k \\geq 0 \\] <p>This means if you start with \\(\\pi\\), applying the matrix dosen\u2019t change it \u2013 it\u2019s a fixed point. </p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#estimating-transition-probabilities-from-data","title":"Estimating Transition Probabilities from Data","text":"<p>If you observe a lot of transitions, you can build a frequency table. Suppose: </p> <ul> <li>\\(n_{ij}\\): number of times we observe a transition from state \\(i\\) to state \\(j\\) </li> </ul> <p>Then the maximum likelihood estimator is:</p> \\[ \\hat{p}{ij} = \\frac{n{ij}}{\\sum_{k=1}^{N} n_{ik}} \\]"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#absorbing-states","title":"Absorbing States","text":"<p>A state is absorbing if: \\(p_{ii} = 1\\), meaning \u2013 once you enter it, you stay there. In finance, default is modeled this way. </p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#visualizing-a-markov-chain-with-credit-ratings","title":"Visualizing a Markov Chain with Credit Ratings","text":"<pre><code>graph TD\n  A[AAA] --&gt;|0.9| A\n  A --&gt;|0.1| B[AA]\n  B --&gt;|0.85| B\n  B --&gt;|0.1| C[A]\n  B --&gt;|0.05| D[Default]\n  C --&gt;|0.8| C\n  C --&gt;|0.2| D\n  D --&gt;|1.0| D</code></pre> <ul> <li>AAA is the best </li> <li>Default is an absorbing state </li> <li>Arrows show probabilities of moving between ratings </li> </ul>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#stationary-distribution_1","title":"Stationary Distribution","text":"<p>Let\u2019s solve for a stationary distribution \\(\\pi\\) in a 2-state example: </p> \\[ P = \\begin{bmatrix} 0.9 &amp; 0.1 \\\\ 0.4 &amp; 0.6 \\end{bmatrix}  \\] <p>We want: </p> \\[ \\pi = [\\pi_1, \\pi_2], \\quad \\text{such that} \\quad \\pi P = \\pi \\] <p>This gives: </p> \\[ \\pi_1 = 0.9 \\pi_1 + 0.4 \\pi_2 \\\\ \\pi_2 = 0.1 \\pi_1 + 0.6 \\pi_2 \\\\ \\pi_1 + \\pi_2 = 1 \\] <p>Solving the first two yields: </p> \\[ \\pi_1 = \\frac{4}{7}, \\quad \\pi_2 = \\frac{3}{7} \\]"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#simplification","title":"Simplification","text":""},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#a-2-state-weather-model","title":"A 2-State Weather Model","text":"<p>Imagine a world where the only two weather states are:</p> <ul> <li>Sunny \ud83c\udf1e </li> <li>Rainy \ud83c\udf27\ufe0f</li> </ul> <p>You\u2019d told: </p> <ul> <li>If today is sunny, there is a 70% chance tomorrow is sunny, 30% chance it will rain. </li> <li>If today is rainy, there is a 60% chance tomorrow is rainy, a 40% chance it will be sunny. </li> </ul> <pre><code>graph LR\nS[\ud83c\udf1e]\nR[\ud83c\udf27\ufe0f]\n\nS--&gt;|0.7|S\nS--&gt;|0.3|R\n\nR--&gt;|0.4|S\nR--&gt;|0.6|R</code></pre> <p>Let\u2019s say today is sunny. Let\u2019s compute: what\u2019s the probability it will be sunny in 2 days? </p> <pre><code>graph LR\n\nS0[\ud83c\udf1e] --&gt;|0.7| S1[\ud83c\udf1e]--&gt;|0.7| S2[\ud83c\udf1e]\nS0[\ud83c\udf1e] --&gt;|0.3| R1[\ud83c\udf27\ufe0f]--&gt;|0.4| S3[\ud83c\udf1e]\nS1[\ud83c\udf1e]--&gt;|0.3| R2[\ud83c\udf27\ufe0f]\nR1[\ud83c\udf27\ufe0f]--&gt;|0.6| R3[\ud83c\udf27\ufe0f]\n</code></pre> <p>So we have:</p> <ul> <li>Sunny in 2 days:<ul> <li>0.7 x 0.7 = 0.49 </li> <li>0.3 x 0.4 =0.12 </li> <li>in total: 0.49 + 0.12 =0.61 </li> </ul> </li> <li>Rainy in 2 days:<ul> <li>0.7 x 0.3 =0.21 </li> <li>0.3 x 0.6 =0.18 </li> <li>in total: 0.21 + 0.18 =0.39 </li> </ul> </li> </ul> <p>So: </p> \\[ P_2(\\text{Sunny}) = 0.61,  P_2(\\text{Rainy}) = 0.39 \\] <p>So we can say that we are tracking how a system moves between states over time. And we are predicting the future \u2013 by using simple rules about the current state. That\u2019s what markov chains are. </p> <p>A method of reasoning about how things change over time, assuming the next step only depends on the current one.</p> <p>This is called the Markov Property.</p> <p>Let:</p> <ul> <li>\\(S_t\\): the state at time \\(t\\) </li> <li>\\(P(S_{t+1} = \\text{sunny} \\mid S_t = \\text{sunny}) = 0.7\\)</li> <li>\\(P(S_{t+1} = \\text{rainy} \\mid S_t = \\text{sunny}) = 0.3\\) </li> <li>Etc.</li> </ul> <p>You only need to look at today to predict tomorrow \u2013 not the whole week\u2019s history. </p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#application-credit-ratings","title":"Application: Credit Ratings","text":"<p>Imagine your credit is rated:</p> <ul> <li>A (great)</li> <li>B (okay)</li> <li>D (default)</li> </ul> <p>Just like the weather, companies transition between credit levels: </p> <ul> <li>A might stay A, or fall to B </li> <li>B might stay B, improve to A, or fall to D </li> <li>D (default) is absorbing: once there, you stay </li> </ul> <p>We can now apply the same simple logic: </p> <p>If a company is B today: </p> <ul> <li>50% chance stays B </li> <li>30% chance to A </li> <li>20% chance to D </li> </ul> <p>We now say, if you have: </p> <ul> <li>\\(n\\) states </li> <li>The transition from state \\(i\\) to state \\(j\\) has probability \\(P_{ij}\\)</li> </ul> <p>Then after two steps: </p> \\[ \\text{Prob(from } i \\text{ to } j \\text{ in 2 steps)} = \\sum_k p_{ik} \\cdot p_{kj} \\] <p>From state A (i) to state C (j) in 2 moves. That means: First you go from A to some intermediate stabe B(k), then from B to C.</p> <p>the full path is: \\(i \\rightarrow k \\rightarrow j\\) , we are just chaining together two-one-step moves.  </p> <p>Let\u2019s say:</p> <ul> <li>\\(P_{ik}\\): Probability to go from i to k in 1 step </li> <li>\\(P_{kj}\\): Probability to go from k to j in 1 step </li> </ul> <p>Then the total probability of the path: \\(i \\rightarrow k \\rightarrow j\\) is simply: \\(P_{ik} \\cdot P_{kj}\\) , you multiply because these two steps are independent events happening in sequence. </p> <p>If there is\u2019nt just one middle state \\(k\\), there could be multiple: </p> \\[ \\begin{aligned} i \\rightarrow k_1 \\rightarrow j \\\\ i \\rightarrow k_2 \\rightarrow j \\\\ i \\rightarrow k_3 \\rightarrow j \\\\ \\text{etc\u2026} \\end{aligned} \\] <p>So to find the total probability of getting from i to j in exactly 2 steps, you must: Add up all those possible paths.</p> <p>If you have 2 total states (say, Sunny and Rainy), then the summation over k \u2014 the intermediate state \u2014 should be: </p> \\[ \\text{Prob(2-step path from } i \\text{ to } j) = \\sum_{k=1}^{2} P_{ik} \\cdot P_{kj}  \\] <p>Where:</p> <ul> <li>\\(i\\) is the starting state</li> <li>\\(j\\) is the ending state</li> <li>\\(k\\) runs over all possible intermediate states (1 and 2 in your case)</li> </ul> <p>If you had 3 states (e.g., A, B, C), then: </p> \\[ \\sum_{k=1}^{3} P_{ik} \\cdot P_{kj} \\] <p>So in general: </p> \\[ \\text{Prob(from } i \\text{ to } j \\text{ in 2 steps)} = \\sum_{k=1}^{n} P_{ik} \\cdot P_{kj}  \\] <p>This formula is scalar-wise computing the (i,j) element of the squared transition matrix, it as a sum of path probabilities. </p> <p>That\u2019s just repeating what we did with sunny/rainy paths! </p> <p>We only need a sum of multiplications. </p> <p>What happens over time? </p> <p>If you run this process over and over (like predicting weather every day), you might find that your probability of being in each state stabilizes. </p> <p>This stable pattern is called the stationary distribution</p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#a-matrix-wise-intuition-for-credit-rating-as-a-markov-chain","title":"A matrix wise intuition for Credit Rating As a Markov Chain","text":"<pre><code>graph TD\n  A[A: High Grade] --&gt;|0.80| A\n  A --&gt;|0.15| B[B: Medium Grade]\n  A --&gt;|0.05| D[**D: Default**]\n  B --&gt;|0.20| A\n  B --&gt;|0.60| B\n  B --&gt;|0.20| D\n  D --&gt;|1.00| D</code></pre> <p>This visual makes it clear that:</p> <ul> <li>A and B can both lead to D (default)</li> <li>D loops to itself (absorbing)</li> </ul> <p>Let\u2019s compute the probability that a company starting in state A ends up in D (default) after 3 years.</p> <p>We list all paths from A to D in 3 steps. You can think of this like all 3-move board game paths:</p> <p>All Possible Paths (A \u2192 \u2026 \u2192 \u2026 \u2192 D): </p> <ol> <li> <p>A \u2192 A \u2192 A \u2192 D:</p> <p>\\(0.8 \\times 0.8 \\times 0.05 = 0.032\\)</p> </li> <li> <p>A \u2192 A \u2192 B \u2192 D:</p> <p>\\(0.8 \\times 0.15 \\times 0.2 = 0.024\\)</p> </li> <li> <p>A \u2192 A \u2192 D \u2192 D:</p> <p>\\(0.8 \\times 0.05 \\times 1 = 0.04\\)</p> </li> <li> <p>A \u2192 B \u2192 B \u2192 D:</p> <p>\\(0.15 \\times 0.6 \\times 0.2 = 0.018\\)</p> </li> <li> <p>A \u2192 B \u2192 A \u2192 D:</p> <p>\\(0.15 \\times 0.2 \\times 0.05 = 0.0015\\)</p> </li> <li> <p>A \u2192 B \u2192 D \u2192 D:</p> <p>\\(0.15 \\times 0.2 \\times 1 = 0.03\\)</p> </li> <li> <p>A \u2192 D \u2192 D \u2192 D:</p> <p>\\(0.05 \\times 1 \\times 1 = 0.05\\)</p> </li> </ol> <p>Add them ALL: \\(P(\\text{A\u2192D in 3 steps}) = 0.032 + 0.024 + 0.04 + 0.018 + 0.0015 + 0.03 + 0.05 = \\boxed{0.1955}\\)</p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#organize-the-probabilities-in-a-table-from-scalars-to-grid","title":"Organize the Probabilities in a Table (From Scalars to Grid)","text":"<p>We already used these scalar transition probabilities: </p> From / To A B D A 0.80 0.15 0.05 B 0.20 0.60 0.20 D 0.00 0.00 1.00 <p>This is now a transition table \u2014 a 2D grid. </p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#turn-that-table-into-a-transition-matrix-p","title":"Turn That Table Into a Transition Matrix P","text":"<p>Now let\u2019s write the same thing using math notation: </p> \\[ P = \\begin{bmatrix} 0.80 &amp; 0.15 &amp; 0.05 \\\\ 0.20 &amp; 0.60 &amp; 0.20 \\\\ 0.00 &amp; 0.00 &amp; 1.00 \\\\ \\end{bmatrix} \\] <p>Each row tells you: from this state, what are the chances of going to all other states. </p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#one-step-probability-as-a-matrix-dot-product","title":"One-Step Probability as a Matrix Dot Product","text":"<p>Let\u2019s say a company is currently in state A.</p> <p>We represent that as a vector:</p> \\[ \\textbf{v}_0 = [1, 0, 0] \\quad \\text{(100\\% in A, 0\\% in B or D)} \\] <p>To find the probabilities after 1 year, you multiply:</p> \\[ \\textbf{v}_1 = \\textbf{v}_0 \\cdot P  \\] \\[ \\textbf{v}_1 = [1, 0, 0] \\cdot \\begin{bmatrix} 0.80 &amp; 0.15 &amp; 0.05 \\\\ 0.20 &amp; 0.60 &amp; 0.20 \\\\ 0.00 &amp; 0.00 &amp; 1.00 \\\\ \\end{bmatrix} = [0.80, 0.15, 0.05] \\] <p>That means:</p> <ul> <li>80% chance in A</li> <li>15% chance in B</li> <li>5% chance in D</li> </ul> <p>Same as the table. </p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#now-try-2-years-multiply-again","title":"Now Try 2 Years \u2014 Multiply Again","text":"<p>To get the probabilities after 2 steps: </p> \\[ \\textbf{v}_2 = \\textbf{v}_1 \\cdot P = [0.80, 0.15, 0.05] \\cdot P \\] <p>We\u2019re now doing exactly what you did in scalar logic \u2014 computing all the 2-step paths \u2014 but doing it much faster with matrix multiplication. </p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#general-rule","title":"General Rule","text":"\\[ \\textbf{v}{t} = \\textbf{v}{t-1} \\cdot P \\quad \\text{or} \\quad \\textbf{v}_t = \\textbf{v}_0 \\cdot P^t \\] <p>You\u2019re simulating how the distribution of ratings evolves over time. </p> <p>So: </p> \\[ \\begin{aligned} \\textbf{v}_1 = \\textbf{v}_0 \\cdot P \\\\ \\textbf{v}_t = \\textbf{v}_0 \\cdot P^t \\end{aligned} \\]"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#summarization","title":"Summarization","text":"<p>A Markov Chain is like walking through a series of states (like credit ratings, weather, or game levels) where the only thing that matters for your next move is where you are right now \u2014 not how you got there.</p> <p>That\u2019s called the Markov property: </p> \\[ P(S_{t+1} = s{\\prime} \\mid S_t = s, S_{t-1}, \u2026, S_0) = P(S_{t+1} = s{\\prime} \\mid S_t = s) \\] <p>Only the current state matters for predicting the next one. That means,  imagine your credit rating today is B. Whether you got downgraded from A or upgraded from C last year doesn\u2019t matter. All that matters is you are B now \u2014 the next step is based on that. </p> <p>RL is about learning how to act in a sequence of situations to get the best long-term reward.</p> <p>At time t:</p> <ul> <li>State: \\(s_t \\in \\mathcal{S}\\)</li> <li>Action: \\(a_t \\in \\mathcal{A}\\)</li> <li>Reward: \\(r_t \\in \\mathcal{R}\\)</li> <li>Next State: \\(s_{t+1} \\in \\mathcal{S}\\)</li> </ul> <p>Goal: Find the best sequence of actions: \\(\\{a_0, a_1, \\ldots, a_t, \\ldots\\}\\)</p> <p>That maximizes cumulative reward over time. This is the big picture \u2014 and Markov chains are the engine beneath the hood. </p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#a-2-state-homogeneous-markov-chain","title":"A 2-State Homogeneous Markov Chain","text":"<ul> <li>States: \\(\\mathcal{S} = \\{s_1, s_2\\}\\), where \\(s_1 &lt; s_2\\)</li> <li>Transition Probabilities:<ul> <li>\\(\\mathbb{P}(S_{t+1} = s_1 | S_t = s_1) = p\\) </li> <li>\\(\\mathbb{P}(S_{t+1} = s_2 | S_t = s_2) = q\\) </li> </ul> </li> </ul> <p>The matrix is:</p> \\[ P = \\begin{bmatrix} p &amp; 1 - p \\\\ 1 - q &amp; q \\end{bmatrix} \\] <p>If each state is associated with a numerical value (e.g., \\(s_1 = -1, s_2 = 1\\)), then multiplying the transition matrix P by the state vector S gives us the expected value of the next state. </p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/02-markov-chain/#code","title":"Code","text":"Python<pre><code>from wqu.sm.markov import StateMarkovChain\n\n\n# Define the state\nstates = [-1, 1]\nP = [\n    [0.55, 0.45],\n    [0.45, 0.55]\n]\n\n# Create the Markov chain instance with initial state -1\nmc = StateMarkovChain(states=states, transition_matrix=P, initial_state=-1)\n\n# Example 1: Simulate a two-step path\nmc.reset(to_state=-1)\npath_two_steps = mc.simulate(2)\n\n# Example 2: Simulate a three-step path\nmc.reset(to_state=-1)\npath_three_steps = mc.simulate(3)\n\n(path_two_steps, path_three_steps)\n</code></pre> Text Only<pre><code>([-1, -1, np.int64(1)], [-1, np.int64(1), np.int64(-1), np.int64(-1)])\n</code></pre> Python<pre><code>mc.plot_trajectory()\n</code></pre> Python<pre><code># Simulating the stochastic process defined by: $X_t = X_{t-1} + s_t$ \n\n# Initialize \nstates = [-1, 1]\nP = [\n    [0.55, 0.45],\n    [0.45, 0.55]\n]\n\nmc = StateMarkovChain(states=states, transition_matrix=P, initial_state=-1)\n\n# Simulate the process X_t = X_{t-1} + s_t for 20 steps\nXt_path, state_path = mc.simulate_X_t_process(steps=20, x0=0)\n\n(Xt_path, state_path)\n</code></pre> Python<pre><code>import matplotlib.pyplot as plt\n\n# Plot the simulated X_t process\nplt.figure(figsize=(10, 5))\nplt.plot(Xt_path, marker='o', label='X_t')\nplt.title(\"Simulated Process $X_t = X_{t-1} + s_t$\")\nplt.xlabel(\"Time Step\")\nplt.ylabel(\"X_t\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</code></pre> Python<pre><code># Plot the simulated S_t process (states)\n\nplt.figure(figsize=(10, 5))\nplt.plot(state_path, marker='o', label='S_t')\nplt.title(\"Simulated Process $S_t$\")\nplt.xlabel(\"Time Step\")\nplt.ylabel(\"S_t\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</code></pre> Python<pre><code># Overlay both X_t and state values s_t on the same plot\ntime = list(range(len(Xt_path)))\n\nfig, ax1 = plt.subplots(figsize=(12, 5))\n\n# Plot X_t\nax1.plot(time, Xt_path, 'o-', color='blue', label='X_t')\nax1.set_xlabel(\"Time Step\")\nax1.set_ylabel(\"$X_t$\", color='blue')\nax1.tick_params(axis='y', labelcolor='blue')\n\n# Plot s_t on secondary axis\nax2 = ax1.twinx()\nax2.step(time, state_path, where='mid', color='orange', linestyle='--', label='s_t (state)')\nax2.set_ylabel(\"State $s_t$\", color='orange')\nax2.tick_params(axis='y', labelcolor='orange')\n\n# Legends and titles\nfig.suptitle(\"Process $X_t = X_{t-1} + s_t$ with Overlayed State Values $s_t$\", fontsize=14)\nax1.grid(True)\nfig.tight_layout()\nplt.show()\n</code></pre> Python<pre><code>states = [-1, 1]\nP = [\n    [0.55, 0.45],\n    [0.45, 0.55]\n]\n\nmc = StateMarkovChain(states, P, initial_state=-1)\nX, s_path, Psim = mc.simulate_X_t(steps=50, x0=75)\n\n# ---- Plot results ----\n\nplt.figure(figsize=(14, 5))\nplt.subplot(1, 2, 1)\nplt.plot(X, marker='o')\nplt.title(\"X_t (Cumulative Process)\")\n\nplt.subplot(1, 2, 2)\nplt.plot(s_path, marker='x')\nplt.title(\"s_t (State Transitions)\")\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Empirical Transition Matrix (Psim):\\n\", Psim)\n</code></pre> Text Only<pre><code>Empirical Transition Matrix (Psim):\n [[12. 14.]\n [13. 10.]]\n</code></pre>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/03-credit-ranking-example/","title":"Credit Ranking Markov Chain Example","text":"<p>The table above shows the actual transition probabilities for credit ratings published by Standard &amp; Poor's (\ud835\udc41\ud835\udc45NR stands for \"rating withdrawn\"). And our objective is to model the transition probabilities for credit ratings using a Markov chain.</p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/03-credit-ranking-example/#step-1-define-the-states","title":"Step 1: Define the states","text":"<p>Python<pre><code># Final code\nimport pandas as pd\n\nraw_matrix_with_nr = np.array([\n    [87.06, 9.06, 0.53, 0.05, 0.11, 0.03, 0.05, 0.0, 3.11],\n    [0.48, 87.23, 7.77, 0.47, 0.05, 0.06, 0.02, 0.02, 3.89],\n    [0.03, 1.6, 88.58, 5.0, 0.26, 0.11, 0.02, 0.05, 4.35],\n    [0, 0.09, 3.25, 86.49, 3.56, 0.43, 0.1, 0.16, 5.92],\n    [0.01, 0.03, 0.11, 4.55, 77.82, 6.8, 0.55, 0.63, 9.51],\n    [0.0, 0.02, 0.07, 0.15, 4.54, 74.6, 4.96, 3.34, 12.33],\n    [0.0, 0.0, 0.1, 0.17, 0.55, 12.47, 43.11, 28.3, 15.31],\n    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0],\n])\n\nraw_state_labels_with_nr = [\"AAA\", \"AA\", \"A\", \"BBB\", \"BB\", \"B\", \"CCC/C\", \"D\", \"NR\"]\npd.DataFrame(raw_matrix_with_nr, columns=raw_state_labels_with_nr, index=raw_state_labels_with_nr[:-1])\n</code></pre> Which results in the following matrix:</p> <p></p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/03-credit-ranking-example/#step-2-normalize-the-matrix","title":"Step 2: Normalize the matrix","text":"<p>Python<pre><code># Drop the NR column and normalize each row so it sums to 1\nnormalized_matrix = raw_matrix_with_nr[:, :-1]\nnormalized_matrix = normalized_matrix / normalized_matrix.sum(axis=1, keepdims=True)\n# Check normalization\nrow_sums = normalized_matrix.sum(axis=1)\nrow_sums\n</code></pre> resulting the following output:</p> <p>Text Only<pre><code>array([1., 1., 1., 1., 1., 1., 1., 1.])\n</code></pre> which confirms that the matrix is normalized.</p>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/03-credit-ranking-example/#step-3-create-the-markov-chain","title":"Step 3: Create the Markov chain","text":"Python<pre><code>from wqu.sm.credit_rating import CreditRatingMarkovChain\n\n# Use standard credit rating labels\nS = [\"AAA\", \"AA\", \"A\", \"BBB\", \"BB\", \"B\", \"CCC/C\", \"D\"]\n# Transition matrix without NR\nP = normalized_matrix\n# Initialize the Markov chain\ncrm = CreditRatingMarkovChain(states=S, transition_matrix=P, initial_state=\"CCC/C\")\n\n# Check the transition matrix (with Pandas DataFrame to make it look nicer)\npd.DataFrame(crm.P, columns=S, index=S)\n</code></pre>"},{"location":"Stochastic%20Modeling/08-reinforcement-learning/03-credit-ranking-example/#step-4-simulate","title":"Step 4: Simulate","text":"Python<pre><code># Simulate a single path\ncrm.simulate_path(steps=100)\n# Plot the path\ncrm.plot_path()\n</code></pre> Python<pre><code># We can also animate the path\ncrm.animate_path()\n</code></pre> Text Only<pre><code># you can also check the full Graph like this:\ncrm.graphviz_chain()\n</code></pre> Python<pre><code># Simulate multiple paths and calculate the default rate\ncrm.simulate_multiple_paths(steps=100, num_simulations=1000)\n</code></pre> Text Only<pre><code>{'simulations': 1000, 'defaulted': 954, 'default_rate': 0.954}\n</code></pre> Python<pre><code># Get the 10th, 200th power of the transition matrix\nP10 = crm.get_matrix_power(10)\nP200 = crm.get_matrix_power(200)\n</code></pre> Python<pre><code>crm.simulate_histories(num_paths=1000, num_steps=100)\ncrm.average_time_to_default()\n</code></pre> Text Only<pre><code>8.332988624612202\n</code></pre>"},{"location":"Stochastic%20Modeling/09-dynamic%20programming/01-dynamic-programming/","title":"Dynamic Programming","text":""}]}